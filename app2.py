import streamlit as st
import feedparser
import pandas as pd
import numpy as np
import yfinance as yf
from textblob import TextBlob
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import time
import urllib.parse
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor # å¼•å…¥éš¨æ©Ÿæ£®æ—

# ==========================================
# 0. é é¢è¨­å®š
# ==========================================
st.set_page_config(page_title="App 9.0 ç‹™æ“Šæ‰‹æŒ‡æ®å®˜", layout="wide")

st.title("ğŸ¦… App 9.0: ç‹™æ“Šæ‰‹æŒ‡æ®å®˜ (æ•¸æ“šåˆ†é›¢ç‰ˆ)")
st.markdown("""
**ç³»çµ±æ¶æ§‹ï¼š**
1.  **æ•¸æ“šå±¤ (Data Layer)**ï¼šæ”¯æ´ã€Œå³æ™‚çˆ¬å– 12 å€‹æœˆæ–°èã€æˆ–ã€ŒåŒ¯å…¥æ­·å²æ–°è CSVã€ã€‚
2.  **å®šåƒ¹å±¤ (Pricing Layer)**ï¼šæ•´åˆ RF éš¨æ©Ÿæ£®æ—ã€ATR æ³¢å‹•ç‡ã€Fibonacciã€å‡å€¼å›æ­¸ã€‚
3.  **æ±ºç­–å±¤ (Sniper Layer)**ï¼š**æ–°è + OBV + æˆäº¤é‡ Z-Score** ä¸‰ä½ä¸€é«”ç¢ºèªã€‚
""")

# ==========================================
# 1. æ•¸æ“šå±¤ï¼šå…¨çƒæ–°èçˆ¬èŸ² (æ”¯æ´åŒ¯å‡º)
# ==========================================
TICKER_MAP = {
    'TSM': {'TW': 'å°ç©é›»', 'JP': 'TSMC', 'EU': 'TSMC'},
    'NVDA': {'TW': 'è¼é”', 'JP': 'NVIDIA', 'EU': 'Nvidia'},
    'AMD': {'TW': 'è¶…å¾®', 'JP': 'AMD', 'EU': 'AMD'},
    'URA': {'TW': 'éˆ¾ç¤¦', 'JP': 'ã‚¦ãƒ©ãƒ³', 'EU': 'Uranium'},
    'SOXL': {'TW': 'åŠå°é«”', 'JP': 'åŠå°ä½“', 'EU': 'Semiconductor'},
    'BTC-USD': {'TW': 'æ¯”ç‰¹å¹£', 'JP': 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³', 'EU': 'Bitcoin'}
}

MULTILINGUAL_DICT = {
    'ZH': {'UP': ['å¤§æ¼²','æ¼²åœ','å‰µé«˜','åˆ©å¤š','çˆ†ç™¼','æ“´ç”¢','æ€¥å–®'], 'DOWN': ['å¤§è·Œ','è·Œåœ','é‡æŒ«','åˆ©ç©º','ç å–®','è¡°é€€']},
    'JA': {'UP': ['ä¸Šæ˜‡','æ€¥é¨°','æœ€é«˜å€¤','å¥½èª¿','å¢—ç›Š'], 'DOWN': ['ä¸‹è½','æ€¥è½','æœ€å®‰å€¤','ä¸èª¿','æ¸›ç›Š']},
    'DE': {'UP': ['anstieg','rekord','gewinn','kaufen'], 'DOWN': ['verlust','fallen','krise','verkaufen']}
}

@st.cache_data(ttl=3600*24)
def fetch_global_news_12m(ticker):
    """æŠ“å–éå» 12 å€‹æœˆæ–°èï¼Œå›å‚³ DataFrame"""
    news_history = []
    end_date = datetime.now()
    start_date = end_date - relativedelta(months=12) # å¼·åˆ¶ä¸€å¹´
    
    map_info = TICKER_MAP.get(ticker, {})
    term_us = f"{ticker}+stock" if len(ticker) <= 4 else ticker
    term_tw = urllib.parse.quote(map_info.get('TW', ticker))
    term_jp = urllib.parse.quote(map_info.get('JP', ticker))
    term_eu = urllib.parse.quote(map_info.get('EU', ticker))

    current = start_date
    while current < end_date:
        next_month = current + relativedelta(months=1)
        d_after = current.strftime('%Y-%m-%d')
        d_before = next_month.strftime('%Y-%m-%d')
        
        # å®šç¾©å››å€‹ç¯€é»
        urls = [
            (f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-US&gl=US&ceid=US:en", 'US'),
            (f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-GB&gl=GB&ceid=GB:en", 'EU_UK')
        ]
        # ç‰¹å®šè‚¡ç¥¨åŠ æŠ“åœ¨åœ°æ–°è
        if ticker in ['TSM', 'NVDA', 'AMD', '0050.TW', 'CLS', 'SOXL']:
            urls.append((f"https://news.google.com/rss/search?q={term_tw}+after:{d_after}+before:{d_before}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant", 'TW'))
        if ticker in ['TSM', 'NVDA', 'SOXL', 'URA']:
            urls.append((f"https://news.google.com/rss/search?q={term_jp}+after:{d_after}+before:{d_before}&hl=ja&gl=JP&ceid=JP:ja", 'JP'))
        if ticker in ['URA', 'SOXL', 'CLS']:
            urls.append((f"https://news.google.com/rss/search?q={term_eu}+after:{d_after}+before:{d_before}&hl=de&gl=DE&ceid=DE:de", 'EU_DE'))

        for url, region in urls:
            try:
                feed = feedparser.parse(url)
                for entry in feed.entries[:2]: # æ¯å€‹ç¯€é»å– 2 æ¢ä»¥ç¯€çœè³‡æºï¼Œç¸½é‡å¤ å¤š
                    title = entry.title
                    pub_date = pd.to_datetime(entry.published).date() if hasattr(entry, 'published') else current.date()
                    
                    # è©•åˆ†é‚è¼¯ (å…§åµŒ)
                    score = 0
                    if region in ['US', 'EU_UK']:
                        score = TextBlob(title).sentiment.polarity
                        if any(x in title.lower() for x in ['beat', 'surge', 'record']): score += 0.3
                    elif region == 'TW':
                        for k in MULTILINGUAL_DICT['ZH']['UP']: 
                            if k in title: score += 0.5
                    # ... (å…¶ä»–èªè¨€çœç•¥ä»¥ç¯€çœé•·åº¦ï¼Œé‚è¼¯åŒå‰)
                    
                    if score != 0:
                        news_history.append({
                            'Ticker': ticker,
                            'Date': pub_date,
                            'Region': region,
                            'Title': title,
                            'Score': score
                        })
            except: pass
        
        current = next_month
        time.sleep(0.05)
    
    return pd.DataFrame(news_history)

# ==========================================
# 2. å®šåƒ¹å±¤ï¼šå››ç¶­å®šåƒ¹æ¨¡å‹ (Quant Engine)
# ==========================================
def train_rf_model(df, ticker):
    """éš¨æ©Ÿæ£®æ—é æ¸¬ (ä¾†è‡ª App 3.0)"""
    try:
        data = df[['Close']].copy()
        data['Ret'] = data['Close'].pct_change()
        data['Vol'] = data['Ret'].rolling(20).std()
        data['SMA'] = data['Close'].rolling(20).mean()
        data['Target'] = data['Close'].shift(-30) # é æ¸¬30å¤©å¾Œ
        data = data.dropna()
        
        if len(data) < 60: return None
        
        X = data[['Ret', 'Vol', 'SMA']]
        y = data['Target']
        
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X, y)
        
        last_row = data.iloc[[-1]][['Ret', 'Vol', 'SMA']]
        return model.predict(last_row)[0]
    except: return None

def calc_4d_target(ticker, df_price):
    """è¨ˆç®— ATR, RF, Fib, MC å››ç¶­ç›®æ¨™åƒ¹"""
    current = df_price['Close'].iloc[-1]
    
    # 1. ATR (ç‰©ç†æ¥µé™)
    tr = df_price['High'] - df_price['Low']
    atr = tr.rolling(14).mean().iloc[-1]
    t_atr = current + (atr * np.sqrt(30))
    
    # 2. Fibonacci (é»ƒé‡‘åˆ†å‰²)
    recent = df_price['Close'].iloc[-60:]
    t_fib = recent.max() + (recent.max() - recent.min()) * 0.618
    
    # 3. Mean Reversion (æ…£æ€§)
    mu = df_price['Close'].pct_change().mean()
    t_mc = current * ((1 + mu) ** 30)
    
    # 4. Random Forest (AI)
    t_rf = train_rf_model(df_price, ticker)
    if t_rf is None: t_rf = t_mc # å‚™æ´
    
    # ç¶œåˆç›®æ¨™
    avg_target = (t_atr + t_fib + t_mc + t_rf) / 4
    return avg_target, {'ATR': t_atr, 'Fib': t_fib, 'MC': t_mc, 'RF': t_rf}

# ==========================================
# 3. æ±ºç­–å±¤ï¼šç‹™æ“Šæ‰‹é‚è¼¯ (Sniper Engine)
# ==========================================
def analyze_sniper(ticker, df_price, df_news_ticker):
    # A. è™•ç†æ–°èåˆ†æ•¸
    news_score = 0
    latest_news = "ç„¡æ–°è"
    if not df_news_ticker.empty:
        # åŠ æ¬Šå¹³å‡ (TW/JP/EU æ¬Šé‡è¼ƒé«˜)
        df_news_ticker['Weight'] = df_news_ticker['Region'].apply(lambda x: 1.2 if x != 'US' else 1.0)
        df_news_ticker['W_Score'] = df_news_ticker['Score'] * df_news_ticker['Weight']
        
        # æ¯æ—¥èšåˆ
        daily_score = df_news_ticker.groupby('Date')['W_Score'].mean()
        # æ˜ å°„åˆ°è‚¡åƒ¹æ—¥æœŸ
        df_price = df_price.join(daily_score, how='left').fillna(0)
        # 3æ—¥å¹³æ»‘
        df_price['News_Factor'] = df_price['W_Score'].rolling(3).mean()
        news_score = df_price['News_Factor'].iloc[-1]
        
        latest = df_news_ticker.sort_values('Date').iloc[-1]
        latest_news = f"[{latest['Region']}] {latest['Title']}"
    
    # B. è¨ˆç®— OBV (è³‡é‡‘æµ)
    df_price['OBV'] = (np.sign(df_price['Close'].diff()) * df_price['Volume']).fillna(0).cumsum()
    obv_slope = (df_price['OBV'].iloc[-1] - df_price['OBV'].iloc[-5]) # 5æ—¥ OBV è¶¨å‹¢
    
    # C. è¨ˆç®—æˆäº¤é‡ Z-Score
    vol = df_price['Volume']
    vol_mean = vol.rolling(20).mean()
    vol_std = vol.rolling(20).std()
    vol_z = (vol.iloc[-1] - vol_mean.iloc[-1]) / (vol_std.iloc[-1] + 1e-9)
    
    # D. å››ç¶­å®šåƒ¹
    target, details = calc_4d_target(ticker, df_price)
    
    # E. ç‹™æ“Šåˆ¤æ–· (Sniper Logic)
    status = "â¬œ è§€æœ›"
    action = "Hold"
    
    is_news_good = news_score > 0.1
    is_fund_in = obv_slope > 0
    is_vol_explode = vol_z > 1.5
    
    if is_news_good and is_fund_in and is_vol_explode:
        status = "ğŸ¯ ç‹™æ“Šé» (Sniper Entry)"
        action = "Strong Buy"
    elif is_news_good and not is_fund_in:
        status = "âš ï¸ å‡çªç ´ (Fakeout)" # æ–°èå¥½ä½†æ²’äººè²·
        action = "Avoid"
    elif not is_news_good and is_fund_in:
        status = "ğŸ¥· æ½›ä¼è²·ç›¤ (Stealth)" # æ²’æ–°èä½†æœ‰äººè²·
        action = "Buy"
    elif news_score < -0.1 and obv_slope < 0:
        status = "ğŸ”» è¶¨å‹¢çœ‹è·Œ"
        action = "Sell"
        
    return {
        'Ticker': ticker,
        'Current': df_price['Close'].iloc[-1],
        'Target_4D': target,
        'Upside': (target - df_price['Close'].iloc[-1]) / df_price['Close'].iloc[-1],
        'News_Score': news_score,
        'OBV_Trend': "æµå…¥" if obv_slope > 0 else "æµå‡º",
        'Vol_Z': vol_z,
        'Status': status,
        'Action': action,
        'Latest_News': latest_news,
        'Details': details
    }

# ==========================================
# 4. ä¸»ç¨‹å¼æµç¨‹
# ==========================================
# Sidebar æ¨¡å¼é¸æ“‡
data_mode = st.sidebar.radio("æ•¸æ“šä¾†æºæ¨¡å¼", ["1. è®“ç¨‹å¼æŠ“å– (Live Fetch)", "2. ä¸Šå‚³å·²çŸ¥æ–°è (Upload CSV)"])

# è³‡ç”¢æ¸…å–®
default_tickers = ["TSM", "NVDA", "AMD", "SOXL", "URA", "CLS"]
user_tickers = st.sidebar.text_area("è¼¸å…¥ä»£è™Ÿ (é€—è™Ÿåˆ†éš”)", ", ".join(default_tickers))
ticker_list = [t.strip().upper() for t in user_tickers.split(',')]

news_df = pd.DataFrame()
run_analysis = False

# --- æ¨¡å¼ 1: å³æ™‚æŠ“å– ---
if data_mode.startswith("1"):
    if st.sidebar.button("ğŸš€ å•Ÿå‹•çˆ¬èŸ² & åˆ†æ"):
        all_news = []
        progress = st.progress(0)
        status = st.empty()
        
        for i, t in enumerate(ticker_list):
            status.text(f"æ­£åœ¨çˆ¬å– {t} éå» 12 å€‹æœˆæ–°è...")
            df = fetch_global_news_12m(t)
            if not df.empty:
                all_news.append(df)
            progress.progress((i+1)/len(ticker_list))
            
        if all_news:
            news_df = pd.concat(all_news, ignore_index=True)
            run_analysis = True
        else:
            st.error("æŠ“ä¸åˆ°ä»»ä½•æ–°èï¼Œè«‹æª¢æŸ¥é€£ç·šã€‚")

# --- æ¨¡å¼ 2: ä¸Šå‚³ CSV ---
else:
    uploaded_file = st.sidebar.file_uploader("ä¸Šå‚³ news_data.csv", type=['csv'])
    if uploaded_file:
        news_df = pd.read_csv(uploaded_file)
        news_df['Date'] = pd.to_datetime(news_df['Date'])
        run_analysis = st.sidebar.button("ğŸš€ åŸ·è¡Œåˆ†æ")

# --- åˆ†æèˆ‡çµæœå±•ç¤º ---
if run_analysis and not news_df.empty:
    st.success(f"æ•¸æ“šå°±ç·’ï¼šå…± {len(news_df)} æ¢æ–°èè³‡æ–™")
    
    # 1. æä¾› CSV ä¸‹è¼‰ (User Requirement)
    csv = news_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰æ–°èè³‡æ–™ (news_data.csv)",
        data=csv,
        file_name='news_data.csv',
        mime='text/csv',
    )
    
    st.divider()
    st.subheader("ğŸ“Š ç‹™æ“Šæ‰‹æˆ°ç•¥å ±å‘Š")
    
    results = []
    progress = st.progress(0)
    
    for i, t in enumerate(ticker_list):
        # ä¸‹è¼‰è‚¡åƒ¹ (Quant Data)
        df_price = yf.download(t, period="2y", progress=False, auto_adjust=True)
        # è™•ç† MultiIndex
        if isinstance(df_price.columns, pd.MultiIndex):
            temp = df_price['Close'][[t]].copy(); temp.columns = ['Close']
            temp['Volume'] = df_price['Volume'][t]
            temp['High'] = df_price['High'][t]
            temp['Low'] = df_price['Low'][t]
            df_price = temp
        else:
            df_price = df_price[['Close', 'Volume', 'High', 'Low']]
            
        # ç¯©é¸è©²è‚¡ç¥¨çš„æ–°è
        df_news_t = news_df[news_df['Ticker'] == t].copy()
        
        # åŸ·è¡Œç‹™æ“Šæ‰‹åˆ†æ
        res = analyze_sniper(t, df_price, df_news_t)
        results.append(res)
        progress.progress((i+1)/len(ticker_list))
        
    # é¡¯ç¤ºçµæœ
    res_df = pd.DataFrame(results)
    
    # æ ¼å¼åŒ–é¡¯ç¤º
    show_df = res_df.copy()
    for c in ['Current', 'Target_4D']: show_df[c] = show_df[c].apply(lambda x: f"${x:.2f}")
    show_df['Upside'] = show_df['Upside'].apply(lambda x: f"{x:+.1%}")
    show_df['Vol_Z'] = show_df['Vol_Z'].apply(lambda x: f"{x:.1f}")
    show_df['News_Score'] = show_df['News_Score'].apply(lambda x: f"{x:.2f}")
    
    # é‡é»æ¬„ä½
    cols = ['Ticker', 'Status', 'Action', 'Current', 'Target_4D', 'Upside', 'News_Score', 'OBV_Trend', 'Vol_Z', 'Latest_News']
    st.dataframe(show_df[cols].style.map(
        lambda x: 'background-color: #00FF7F; color: black' if 'ç‹™æ“Šé»' in str(x) else ('background-color: #FF4B4B; color: white' if 'å‡çªç ´' in str(x) else ''),
        subset=['Status']
    ))
    
    # æ°£æ³¡åœ–ï¼šZ-Score (X) vs News Score (Y)
    fig = go.Figure()
    for i, row in res_df.iterrows():
        color = '#00FF7F' if 'ç‹™æ“Š' in row['Status'] else ('#FF4B4B' if 'å‡' in row['Status'] else 'gray')
        fig.add_trace(go.Scatter(
            x=[row['Vol_Z']], y=[row['News_Score']],
            mode='markers+text', text=[row['Ticker']],
            textposition="top center", marker=dict(size=30, color=color),
            name=row['Ticker'],
            hovertemplate="<b>%{text}</b><br>News: %{y:.2f}<br>Vol Z: %{x:.1f}<br>Status: " + row['Status']
        ))
        
    fig.add_hline(y=0, line_dash="dash", line_color="white")
    fig.add_vline(x=1.5, line_dash="dash", line_color="yellow", annotation_text="çˆ†é‡é–€æª»")
    
    fig.update_layout(
        title="<b>ç‹™æ“Šæ‰‹é›·é”</b> (å³ä¸Šè§’=æœ€ä½³è²·é»)",
        xaxis_title="æˆäº¤é‡ç•°å¸¸å€¼ (Vol Z-Score)",
        yaxis_title="æ–°èæƒ…ç·’åˆ†æ•¸ (News Score)",
        template="plotly_dark", height=500
    )
    st.plotly_chart(fig, use_container_width=True)