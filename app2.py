import streamlit as st
import feedparser
import pandas as pd
import numpy as np
import yfinance as yf
from textblob import TextBlob
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import time
import urllib.parse
import os
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor

# ==========================================
# 0. é é¢è¨­å®šèˆ‡æœ¬æ©Ÿæª”æ¡ˆ
# ==========================================
st.set_page_config(page_title="App 12.0 çµ‚æ¥µæŒ‡æ®å®˜", layout="wide")
LOCAL_NEWS_FILE = "news_data_local.csv"

# åˆå§‹åŒ– Session State
if 'news_data' not in st.session_state:
    if os.path.exists(LOCAL_NEWS_FILE):
        try:
            df_local = pd.read_csv(LOCAL_NEWS_FILE)
            if 'Date' in df_local.columns:
                df_local['Date'] = pd.to_datetime(df_local['Date'])
            st.session_state['news_data'] = df_local
        except: st.session_state['news_data'] = pd.DataFrame()
    else: st.session_state['news_data'] = pd.DataFrame()

st.title("ğŸ¦… App 12.0: çµ‚æ¥µæŒ‡æ®å®˜ (Macro + Fund + Quant + News)")
st.markdown("""
**é›†å¤§æˆä¹‹ä½œï¼š**
1.  **å®è§€å¤©çœ¼ (Macro)**ï¼šDXY/TNX/HYG æ±ºå®šç´…ç¶ ç‡ˆã€‚
2.  **åŸºæœ¬é¢ä¿®æ­£ (Fund)**ï¼šè²¡å ±æ•¸æ“šä¿®æ­£ç›®æ¨™åƒ¹ (Scalar)ã€‚
3.  **é›™é‡æˆ°è¡“å›æ¸¬**ï¼šåŒæ™‚é©—è­‰ **ã€Œé †å‹¢ç‹™æ“Šã€** èˆ‡ **ã€Œé€†å‹¢æŠ„åº•ã€** å‹ç‡ã€‚
4.  **æ–¹å‘æº–ç¢ºåº¦ (Dir_Acc)**ï¼šæª¢é©—æ¨¡å‹é•·æœŸé æ¸¬èƒ½åŠ›ã€‚
""")

# ==========================================
# 1. ç¬¬ä¸€å±¤ï¼šå®è§€å¤©çœ¼ (Macro Regime)
# ==========================================
@st.cache_data(ttl=3600*4)
def fetch_macro_context():
    tickers = ['DX-Y.NYB', '^TNX', 'HYG', '^VIX']
    data = yf.download(tickers, period="1y", progress=False)['Close']
    
    # è¶¨å‹¢
    dxy = data['DX-Y.NYB']
    dxy_ma = dxy.rolling(20).mean().iloc[-1]
    
    tnx = data['^TNX']
    tnx_ma = tnx.rolling(20).mean().iloc[-1]
    
    hyg = data['HYG']
    hyg_ma = hyg.rolling(20).mean().iloc[-1]
    
    vix = data['^VIX'].iloc[-1]
    
    # è©•åˆ† (Risk-On Score)
    score = 0
    if dxy.iloc[-1] < dxy_ma: score += 1      # ç¾å…ƒå¼± -> åŠ åˆ†
    if tnx.iloc[-1] < tnx_ma: score += 1      # åˆ©ç‡é™ -> åŠ åˆ†
    if hyg.iloc[-1] > hyg_ma: score += 1      # è°æ˜éŒ¢è²·å‚µ -> åŠ åˆ†
    if vix < 20: score += 1                   # ä¸ææ…Œ -> åŠ åˆ†
    
    regime = "ğŸŸ¢ ç¶ ç‡ˆ (ç©æ¥µ)" if score >= 3 else ("ğŸŸ¡ é»ƒç‡ˆ (è¬¹æ…)" if score == 2 else "ğŸ”´ ç´…ç‡ˆ (ä¿å®ˆ)")
    
    return {'Regime': regime, 'Score': score, 'Raw': data}

# ==========================================
# 2. ç¬¬äºŒå±¤ï¼šåŸºæœ¬é¢ç´”é‡ (Fundamental Scalar)
# ==========================================
@st.cache_data(ttl=3600*24)
def get_fundamental_scalar(ticker):
    """
    å¾ App 3.0 ç§»æ¤ï¼šæ ¹æ“šè²¡å ±ä¿®æ­£ç›®æ¨™åƒ¹ (0.85 ~ 1.15)
    """
    try:
        if ticker in ['BTC-USD', 'URA', 'TLT', '0050.TW']: return 1.0, "ETF/Crypto" # éå€‹è‚¡è·³é
        
        stock = yf.Ticker(ticker)
        info = stock.info
        fins = stock.quarterly_financials
        if fins.empty: return 1.0, "No Data"

        score = 0
        
        # A. ç‡Ÿæ”¶æˆé•·
        if 'Total Revenue' in fins.index and len(fins.columns) >= 2:
            r_now = fins.loc['Total Revenue'].iloc[0]
            r_prev = fins.loc['Total Revenue'].iloc[1]
            growth = (r_now - r_prev) / r_prev if r_prev != 0 else 0
            if growth > 0.10: score += 1
            elif growth < -0.05: score -= 1
            
        # B. ç²åˆ©èƒ½åŠ›
        if 'Net Income' in fins.index:
            ni = fins.loc['Net Income'].iloc[0]
            if ni > 0: score += 1
            else: score -= 1
            
        # C. P/E æª¢æŸ¥
        pe = info.get('trailingPE')
        if pe:
            if pe > 60: score -= 1 # éç†±
            elif pe < 15 and pe > 0: score += 1 # åƒ¹å€¼
            
        scalar = 1.0 + (score * 0.05)
        return max(0.85, min(1.15, scalar)), f"Score: {score}"
        
    except: return 1.0, "Error"

# ==========================================
# 3. æ•¸æ“šå±¤ï¼šå…¨çƒæ–°è (å«æœ¬æ©Ÿå­˜æª”)
# ==========================================
TICKER_MAP = {
    'TSM': {'TW': 'å°ç©é›»', 'JP': 'TSMC', 'EU': 'TSMC'},
    'NVDA': {'TW': 'è¼é”', 'JP': 'NVIDIA', 'EU': 'Nvidia'},
    'AMD': {'TW': 'è¶…å¾®', 'JP': 'AMD', 'EU': 'AMD'},
    'URA': {'TW': 'éˆ¾ç¤¦', 'JP': 'ã‚¦ãƒ©ãƒ³', 'EU': 'Uranium'},
    'SOXL': {'TW': 'åŠå°é«”', 'JP': 'åŠå°ä½“', 'EU': 'Semiconductor'},
    'BTC-USD': {'TW': 'æ¯”ç‰¹å¹£', 'JP': 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³', 'EU': 'Bitcoin'}
}

def fetch_global_news_12m(ticker):
    news_history = []
    end_date = datetime.now()
    start_date = end_date - relativedelta(months=12) 
    map_info = TICKER_MAP.get(ticker, {})
    term_us = f"{ticker}+stock" if len(ticker) <= 4 else ticker
    term_tw = urllib.parse.quote(map_info.get('TW', ticker))
    term_jp = urllib.parse.quote(map_info.get('JP', ticker))
    term_eu = urllib.parse.quote(map_info.get('EU', ticker))

    current = start_date
    while current < end_date:
        next_month = current + relativedelta(months=1)
        d_after = current.strftime('%Y-%m-%d')
        d_before = next_month.strftime('%Y-%m-%d')
        
        urls = [
            (f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-US&gl=US&ceid=US:en", 'US'),
            (f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-GB&gl=GB&ceid=GB:en", 'EU_UK')
        ]
        if ticker in ['TSM', 'NVDA', 'AMD', '0050.TW', 'CLS', 'SOXL']:
            urls.append((f"https://news.google.com/rss/search?q={term_tw}+after:{d_after}+before:{d_before}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant", 'TW'))
        if ticker in ['TSM', 'NVDA', 'SOXL', 'URA', 'BTC-USD']:
            urls.append((f"https://news.google.com/rss/search?q={term_jp}+after:{d_after}+before:{d_before}&hl=ja&gl=JP&ceid=JP:ja", 'JP'))
        if ticker in ['URA', 'SOXL', 'CLS', 'AMD']:
            urls.append((f"https://news.google.com/rss/search?q={term_eu}+after:{d_after}+before:{d_before}&hl=de&gl=DE&ceid=DE:de", 'EU_DE'))

        for url, region in urls:
            try:
                feed = feedparser.parse(url)
                for entry in feed.entries[:2]: 
                    title = entry.title
                    pub_date = pd.to_datetime(entry.published).date() if hasattr(entry, 'published') else current.date()
                    score = 0
                    if region in ['US', 'EU_UK']:
                        score = TextBlob(title).sentiment.polarity
                        if any(x in title.lower() for x in ['beat', 'surge', 'record']): score += 0.3
                    elif region == 'TW' and 'TW' in map_info:
                        if 'æ¼²' in title or 'é«˜' in title: score += 0.5
                    # ... ç°¡åŒ–é‚è¼¯ä»¥ç¯€çœä»£ç¢¼ç©ºé–“
                    
                    if score != 0:
                        news_history.append({'Ticker': ticker, 'Date': pub_date, 'Region': region, 'Title': title, 'Score': score})
            except: pass
        current = next_month
        time.sleep(0.05)
    return pd.DataFrame(news_history)

# ==========================================
# 4. ç¬¬äºŒå±¤ï¼šå››ç¶­å®šåƒ¹ (Quant Engine)
# ==========================================
def train_rf_model(df, ticker):
    try:
        data = df[['Close']].copy()
        data['Ret'] = data['Close'].pct_change()
        data['Vol'] = data['Ret'].rolling(20).std()
        data['SMA'] = data['Close'].rolling(20).mean()
        data['Target'] = data['Close'].shift(-22) # 22å¤©é æ¸¬ (é…åˆ Dir_Acc)
        data = data.dropna()
        if len(data) < 60: return None
        X = data[['Ret', 'Vol', 'SMA']]
        y = data['Target']
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X, y)
        last_row = data.iloc[[-1]][['Ret', 'Vol', 'SMA']]
        return model.predict(last_row)[0]
    except: return None

def calc_4d_target(ticker, df_price, scalar):
    current = df_price['Close'].iloc[-1]
    tr = df_price['High'] - df_price['Low']
    atr = tr.rolling(14).mean().iloc[-1]
    t_atr = current + (atr * np.sqrt(22))
    recent = df_price['Close'].iloc[-60:]
    t_fib = recent.max() + (recent.max() - recent.min()) * 0.618
    mu = df_price['Close'].pct_change().mean()
    t_mc = current * ((1 + mu) ** 22)
    t_rf = train_rf_model(df_price, ticker)
    if t_rf is None: t_rf = t_mc
    
    avg_target = (t_atr + t_fib + t_mc + t_rf) / 4
    # å¥—ç”¨åŸºæœ¬é¢ä¿®æ­£ (Scalar)
    final_target = avg_target * scalar
    return final_target

# ==========================================
# 5. ç¬¬ä¸‰å±¤ï¼šé›™é‡å›æ¸¬ (Dir_Acc + Strategy)
# ==========================================
def run_dual_backtest(df_price, df_news_ticker, macro_data):
    df = df_price.copy()
    
    # 1. æ•´åˆæ–°è
    if not df_news_ticker.empty:
        if not pd.api.types.is_datetime64_any_dtype(df_news_ticker['Date']):
             df_news_ticker['Date'] = pd.to_datetime(df_news_ticker['Date'])
        df_news_ticker['Weight'] = df_news_ticker['Region'].apply(lambda x: 1.2 if x != 'US' else 1.0)
        df_news_ticker['W_Score'] = df_news_ticker['Score'] * df_news_ticker['Weight']
        daily_score = df_news_ticker.groupby('Date')['W_Score'].mean()
        df = df.join(daily_score, how='left').fillna(0)
        df['News_Roll'] = df['W_Score'].rolling(3).mean()
    else:
        df['News_Roll'] = 0
        
    # 2. æ•´åˆå®è§€ (Risk-On)
    macro_aligned = macro_data.reindex(df.index).ffill()
    macro_aligned['HYG_MA'] = macro_aligned['HYG'].rolling(20).mean()
    macro_aligned['Risk_On'] = macro_aligned['HYG'] > macro_aligned['HYG_MA']
    df = df.join(macro_aligned[['Risk_On']], how='left').fillna(False)

    # 3. æŠ€è¡“æŒ‡æ¨™ (OBV, Vol_Z, Bias)
    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
    df['OBV_Slope'] = df['OBV'].diff(5)
    
    df['MA20'] = df['Close'].rolling(20).mean()
    df['Bias'] = (df['Close'] - df['MA20']) / df['MA20']
    
    vol_mean = df['Volume'].rolling(20).mean()
    vol_std = df['Volume'].rolling(20).std()
    df['Vol_Z'] = (df['Volume'] - vol_mean) / (vol_std + 1e-9)
    
    # 4. ç›®æ¨™è®Šæ•¸ (22å¤©å›å ±ï¼Œç”¨æ–¼ Dir_Acc)
    df['Ret_1M'] = df['Close'].shift(-22) / df['Close'] - 1
    # ç›®æ¨™è®Šæ•¸ (5å¤©å›å ±ï¼Œç”¨æ–¼æˆ°è¡“å›æ¸¬)
    df['Ret_5D'] = df['Close'].shift(-5) / df['Close'] - 1
    
    # --- Metric 1: Dir_Acc (é•·æœŸæ–¹å‘) ---
    # çµåˆ News + OBV + Tech
    df['Alpha_Raw'] = (df['News_Roll'] * 0.4) + (np.sign(df['OBV_Slope']).fillna(0) * 0.3) + (np.where(df['Bias']>0, 1, -1) * 0.3)
    valid_dir = df.dropna(subset=['Ret_1M', 'Alpha_Raw'])
    if len(valid_dir) > 0:
        correct = (valid_dir['Alpha_Raw'] * valid_dir['Ret_1M']) > 0
        dir_acc = correct.mean()
    else: dir_acc = 0.5
    
    # --- Metric 2: Sniper Win (é †å‹¢ç‹™æ“Š) ---
    # æ¢ä»¶: News>0.1 & OBV>0 & Vol_Z>1.5 & Risk_On
    # é æ¸¬: 5å¤©å¾Œæ¼²
    sniper_mask = (df['News_Roll'] > 0.1) & (df['OBV_Slope'] > 0) & (df['Vol_Z'] > 1.5) & (df['Risk_On'] == True)
    sniper_opps = df[sniper_mask].dropna(subset=['Ret_5D'])
    if len(sniper_opps) > 0:
        sniper_win = len(sniper_opps[sniper_opps['Ret_5D'] > 0]) / len(sniper_opps)
    else: sniper_win = 0.0
    
    # --- Metric 3: Antifragile Win (é€†å‹¢æŠ„åº•) ---
    # æ¢ä»¶: News<-0.1 (å£æ¶ˆæ¯) & Bias<-0.05 (è¶…è³£)
    # é æ¸¬: 5å¤©å¾Œæ¼² (åå½ˆ)
    anti_mask = (df['News_Roll'] < -0.1) & (df['Bias'] < -0.05)
    anti_opps = df[anti_mask].dropna(subset=['Ret_5D'])
    if len(anti_opps) > 0:
        anti_win = len(anti_opps[anti_opps['Ret_5D'] > 0]) / len(anti_opps)
    else: anti_win = 0.0
    
    # å›å‚³æœ€å¾Œä¸€å¤©çš„æŒ‡æ¨™ä¾›è¨Šè™Ÿåˆ¤æ–·
    last_row = df.iloc[-1]
    last_metrics = {
        'News': last_row['News_Roll'],
        'OBV': last_row['OBV_Slope'],
        'Vol_Z': last_row['Vol_Z'],
        'Bias': last_row['Bias'],
        'Risk_On': last_row['Risk_On']
    }
    
    return dir_acc, sniper_win, anti_win, len(sniper_opps), len(anti_opps), last_metrics

# ==========================================
# 6. ä¸»ç¨‹å¼
# ==========================================
st.sidebar.title("æ§åˆ¶å°")
data_mode = st.sidebar.radio("æ•¸æ“šä¾†æº", ["1. å„ªå…ˆä½¿ç”¨æœ¬æ©Ÿ/è¨˜æ†¶é«”", "2. å¼·åˆ¶é‡æŠ“", "3. ä¸Šå‚³ CSV"])
default_tickers = ["TSM", "NVDA", "AMD", "SOXL", "URA", "CLS", "0050.TW"]
user_tickers = st.sidebar.text_area("ä»£è™Ÿ", ", ".join(default_tickers))
ticker_list = [t.strip().upper() for t in user_tickers.split(',')]

# å®è§€çœ‹æ¿
macro_info = fetch_macro_context()
st.subheader(f"ğŸŒ å®è§€å¤©çœ¼: {macro_info['Regime']} (Score: {macro_info['Score']})")
c1, c2, c3, c4 = st.columns(4)
c1.metric("ç¾å…ƒ (Risk-Off)", f"{macro_info['Raw']['DX-Y.NYB'].iloc[-1]:.2f}")
c2.metric("æ®–åˆ©ç‡ (Valuation)", f"{macro_info['Raw']['^TNX'].iloc[-1]:.2f}")
c3.metric("é¢¨éšªå‚µ (Risk-On)", f"{macro_info['Raw']['HYG'].iloc[-1]:.2f}")
c4.metric("åŸºæœ¬é¢ä¿®æ­£", "å•Ÿå‹•")
st.divider()

# è³‡æ–™è™•ç†
if data_mode.startswith("2"):
    if st.sidebar.button("ğŸš€ å•Ÿå‹•çˆ¬èŸ²"):
        all_news = []
        bar = st.sidebar.progress(0)
        for i, t in enumerate(ticker_list):
            df = fetch_global_news_12m(t)
            if not df.empty: all_news.append(df)
            bar.progress((i+1)/len(ticker_list))
        if all_news:
            news_df = pd.concat(all_news, ignore_index=True)
            st.session_state['news_data'] = news_df
            news_df.to_csv(LOCAL_NEWS_FILE, index=False)
            st.sidebar.success("æ›´æ–°æˆåŠŸ")

elif data_mode.startswith("3"):
    up = st.sidebar.file_uploader("ä¸Šå‚³", type=['csv'])
    if up:
        try:
            temp = pd.read_csv(up)
            temp['Date'] = pd.to_datetime(temp['Date'])
            st.session_state['news_data'] = temp
            temp.to_csv(LOCAL_NEWS_FILE, index=False)
        except: st.error("å¤±æ•—")

# åˆ†æåŸ·è¡Œ
if st.button("ğŸš€ åŸ·è¡Œçµ‚æ¥µåˆ†æ"):
    if st.session_state['news_data'].empty:
        st.error("ç„¡æ•¸æ“š")
    else:
        st.sidebar.download_button("ğŸ“¥ ä¸‹è¼‰æ–°è", st.session_state['news_data'].to_csv(index=False).encode('utf-8'), "news.csv")
        st.subheader("ğŸ“Š çµ‚æ¥µæˆ°ç•¥å ±å‘Š")
        
        news_df = st.session_state['news_data']
        results = []
        
        for t in ticker_list:
            # 1. æŠ“è‚¡åƒ¹
            df_price = yf.download(t, period="2y", progress=False, auto_adjust=True)
            if isinstance(df_price.columns, pd.MultiIndex):
                temp = df_price['Close'][[t]].copy(); temp.columns = ['Close']
                temp['Volume'] = df_price['Volume'][t]
                temp['High'] = df_price['High'][t]
                temp['Low'] = df_price['Low'][t]
                df_price = temp
            else:
                df_price = df_price[['Close', 'Volume', 'High', 'Low']]
            
            # 2. æŠ“å€‹è‚¡æ–°è
            df_news_t = news_df[news_df['Ticker'] == t].copy()
            
            # 3. é›™é‡å›æ¸¬
            dir_acc, sn_win, an_win, sn_cnt, an_cnt, metrics = run_dual_backtest(df_price, df_news_t, macro_info['Raw'])
            
            # 4. åŸºæœ¬é¢ Scalar
            scalar, fund_note = get_fundamental_scalar(t)
            
            # 5. å››ç¶­å®šåƒ¹
            target = calc_4d_target(t, df_price, scalar)
            current = df_price['Close'].iloc[-1]
            
            # 6. è¨Šè™Ÿç”Ÿæˆ (æ•´åˆ Macro)
            signal = "â¬œ è§€æœ›"
            # å¿…é ˆ Risk-On æ‰èƒ½åšç‹™æ“Š
            if metrics['Risk_On'] and metrics['News'] > 0.1 and metrics['OBV'] > 0 and metrics['Vol_Z'] > 1.5:
                signal = "ğŸ¯ é †å‹¢ç‹™æ“Š"
            # é€†å‹¢æŠ„åº•ä¸ä¸€å®šéœ€è¦ Risk-On (å› ç‚ºæ˜¯æ¶åå½ˆ)
            elif metrics['News'] < -0.1 and metrics['Bias'] < -0.05:
                signal = "ğŸ’ é€†å‹¢æŠ„åº•"
            
            results.append({
                'Ticker': t,
                'Dir_Acc': dir_acc,
                'Sniper_Win': sn_win,
                'Anti_Win': an_win,
                'Current': current,
                'Target': target,
                'Upside': (target-current)/current,
                'Fund_Scalar': scalar,
                'Signal': signal,
                'Risk_On': "YES" if metrics['Risk_On'] else "NO"
            })
            
        res_df = pd.DataFrame(results)
        
        # é¡¯ç¤º
        show = res_df.copy()
        show['Dir_Acc'] = show['Dir_Acc'].apply(lambda x: f"{x:.0%}")
        show['Sniper_Win'] = show['Sniper_Win'].apply(lambda x: f"{x:.0%}")
        show['Anti_Win'] = show['Anti_Win'].apply(lambda x: f"{x:.0%}")
        show['Upside'] = show['Upside'].apply(lambda x: f"{x:+.1%}")
        show['Current'] = show['Current'].apply(lambda x: f"${x:.2f}")
        show['Target'] = show['Target'].apply(lambda x: f"${x:.2f}")
        show['Fund_Scalar'] = show['Fund_Scalar'].apply(lambda x: f"x{x:.2f}")

        st.dataframe(show[['Ticker', 'Signal', 'Dir_Acc', 'Sniper_Win', 'Anti_Win', 'Upside', 'Target', 'Fund_Scalar', 'Risk_On']].style.map(
            lambda x: 'background-color: #00FF7F; color: black' if 'ç‹™æ“Š' in str(x) else ('background-color: #00BFFF; color: black' if 'æŠ„åº•' in str(x) else ''), 
            subset=['Signal']
        ))
        
        st.info("ğŸ’¡ Dir_Acc (æ–¹å‘æº–ç¢ºåº¦) ä»£è¡¨é•·æœŸé«”è³ªï¼›Sniper/Anti Win ä»£è¡¨ç‰¹å®šæˆ°è¡“å‹ç‡ã€‚è«‹æ ¹æ“šè³‡ç”¢æ€§æ ¼é¸æ“‡æˆ°è¡“ã€‚")