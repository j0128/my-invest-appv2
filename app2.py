import streamlit as st
import feedparser
import pandas as pd
import numpy as np
import yfinance as yf
from textblob import TextBlob
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import time
import urllib.parse
import plotly.graph_objects as go

# ==========================================
# 0. é é¢è¨­å®š
# ==========================================
st.set_page_config(page_title="App 8.1 å…¨çƒæƒ…å ±ç¶²", layout="wide")

st.title("ğŸ¦… App 8.1: å…¨çƒæƒ…å ±ç¶² (ç¾/å°/æ—¥/æ­ å››æ ¸å¿ƒ)")
st.markdown("""
**æˆ°ç•¥åœ°åœ–å…¨é–‹ï¼š**
1.  **ğŸ‡ºğŸ‡¸ ç¾åœ‹ (US)**ï¼šå…¨çƒè³‡é‡‘å…±è­˜ (NVDA, BTC, META)ã€‚
2.  **ğŸ‡¹ğŸ‡¼ å°ç£ (TW)**ï¼šåŠå°é«”è£½é€ å…§å¹• (TSM)ã€‚
3.  **ğŸ‡¯ğŸ‡µ æ—¥æœ¬ (JP)**ï¼šææ–™è¨­å‚™ä¸Šæ¸¸ (SOXL)ã€‚
4.  **ğŸ‡ªğŸ‡º æ­æ´² (EU)**ï¼šæ ¸èƒ½èˆ‡è¨­å‚™å·¨é ­ (URA, ASML)ã€‚
""")

# ==========================================
# 1. å¤šèªè¨€é‡‘èå­—å…¸ (å«å¾·æ–‡)
# ==========================================
MULTILINGUAL_DICT = {
    'ZH': { # ä¸­æ–‡ (TW)
        'UP': ['å¤§æ¼²', 'æ¼²åœ', 'å‰µé«˜', 'æ–°é«˜', 'åˆ©å¤š', 'å„ªæ–¼é æœŸ', 'çˆ†ç™¼', 'æ“´ç”¢', 'å®ŒéŠ·', 'æ€¥å–®', 'çœ‹å¥½', 'è²·é€²', 'åŠ ç¢¼', 'æˆé•·'],
        'DOWN': ['å¤§è·Œ', 'è·Œåœ', 'é‡æŒ«', 'æ–°ä½', 'åˆ©ç©º', 'ä¸å¦‚é æœŸ', 'ç å–®', 'è¡°é€€', 'è™§æ', 'è£å“¡', 'çœ‹å£', 'è³£å‡º', 'æ¸›ç¢¼', 'ç–²å¼±']
    },
    'JA': { # æ—¥æ–‡ (JP)
        'UP': ['ä¸Šæ˜‡', 'æ€¥é¨°', 'æœ€é«˜å€¤', 'å¥½èª¿', 'å¢—ç›Š', 'æœ€é«˜ç›Š', 'è²·å', 'ææº', 'æ‹¡å¤§', 'å›å¾©', 'æœŸå¾…', 'ã‚¹ãƒˆãƒƒãƒ—é«˜'],
        'DOWN': ['ä¸‹è½', 'æ€¥è½', 'æœ€å®‰å€¤', 'ä¸èª¿', 'æ¸›ç›Š', 'èµ¤å­—', 'æ’¤é€€', 'ä¸­æ­¢', 'ç¸®å°', 'æ‡¸å¿µ', 'å¤±æœ›', 'ã‚¹ãƒˆãƒƒãƒ—å®‰']
    },
    'DE': { # å¾·æ–‡ (EU)
        'UP': ['anstieg', 'rekord', 'gewinn', 'kaufen', 'bullisch', 'wachstum', 'erholung', 'hoch', 'positiv', 'Ã¼bertreffen'],
        'DOWN': ['verlust', 'fallen', 'krise', 'verkaufen', 'bÃ¤risch', 'rÃ¼ckgang', 'tief', 'negativ', 'warnung', 'absturz']
    }
}

# è‚¡ç¥¨ä»£è™Ÿè‡ªå‹•ç¿»è­¯æ©Ÿ
TICKER_MAP = {
    'TSM': {'TW': 'å°ç©é›»', 'JP': 'TSMC', 'EU': 'TSMC'},
    'NVDA': {'TW': 'è¼é”', 'JP': 'NVIDIA', 'EU': 'Nvidia'},
    'AMD': {'TW': 'è¶…å¾®', 'JP': 'AMD', 'EU': 'AMD'},
    'URA': {'TW': 'éˆ¾ç¤¦', 'JP': 'ã‚¦ãƒ©ãƒ³', 'EU': 'Uranium'}, # URA é—œéµ
    'ASML': {'TW': 'è‰¾å¸æ‘©çˆ¾', 'JP': 'ASML', 'EU': 'ASML'},
    'SOXL': {'TW': 'åŠå°é«”', 'JP': 'åŠå°ä½“', 'EU': 'Semiconductor'},
    'BTC-USD': {'TW': 'æ¯”ç‰¹å¹£', 'JP': 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³', 'EU': 'Bitcoin'}
}

# ==========================================
# 2. å…¨çƒ RSS é§­å®¢ (ç¾/å°/æ—¥/æ­)
# ==========================================
@st.cache_data(ttl=3600*12) 
def fetch_global_news(ticker, months=12):
    news_history = []
    end_date = datetime.now()
    start_date = end_date - relativedelta(months=months)
    
    # æº–å‚™æœå°‹é—œéµå­—
    map_info = TICKER_MAP.get(ticker, {})
    
    # è‹±æ–‡é—œéµå­— (ç¾/è‹±)
    term_us = f"{ticker}+stock" if len(ticker) <= 4 else ticker
    
    # åœ¨åœ°é—œéµå­—
    term_tw = urllib.parse.quote(map_info.get('TW', ticker))
    term_jp = urllib.parse.quote(map_info.get('JP', ticker))
    term_eu = urllib.parse.quote(map_info.get('EU', ticker)) # æ­æ´²é—œéµå­—

    current = start_date
    while current < end_date:
        next_month = current + relativedelta(months=1)
        d_after = current.strftime('%Y-%m-%d')
        d_before = next_month.strftime('%Y-%m-%d')
        
        # --- 1. US Node (ç¾) ---
        url_us = f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-US&gl=US&ceid=US:en"
        parse_rss_feed(url_us, 'US', news_history, current.date())
        
        # --- 2. TW Node (å°) ---
        if ticker in ['TSM', 'NVDA', 'AMD', '0050.TW', 'CLS', 'SOXL'] or '.TW' in ticker:
            url_tw = f"https://news.google.com/rss/search?q={term_tw}+after:{d_after}+before:{d_before}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
            parse_rss_feed(url_tw, 'TW', news_history, current.date())
            
        # --- 3. JP Node (æ—¥) ---
        if ticker in ['TSM', 'NVDA', 'AMD', 'SOXL', 'BTC-USD', 'URA']: # æ—¥æœ¬é‡å•Ÿæ ¸èƒ½ï¼ŒURA ç›¸é—œ
            url_jp = f"https://news.google.com/rss/search?q={term_jp}+after:{d_after}+before:{d_before}&hl=ja&gl=JP&ceid=JP:ja"
            parse_rss_feed(url_jp, 'JP', news_history, current.date())

        # --- 4. EU Node (æ­ - å¾·/è‹±) ---
        # é‡å° URA (æ ¸èƒ½), SOXL (ASML), CLS (å…¨çƒä½ˆå±€), TLT (æ­å‚µå½±éŸ¿)
        if ticker in ['URA', 'SOXL', 'CLS', 'TLT', 'BTC-USD', 'AMD']:
            # å¾·åœ‹ (DE) - æŠ“å·¥æ¥­/æ ¸èƒ½
            url_de = f"https://news.google.com/rss/search?q={term_eu}+after:{d_after}+before:{d_before}&hl=de&gl=DE&ceid=DE:de"
            parse_rss_feed(url_de, 'EU_DE', news_history, current.date())
            
            # è‹±åœ‹ (UK) - æŠ“é‡‘èå…±è­˜
            url_uk = f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-GB&gl=GB&ceid=GB:en"
            parse_rss_feed(url_uk, 'EU_UK', news_history, current.date())

        current = next_month
        time.sleep(0.1) 
        
    if not news_history: return pd.DataFrame(columns=['Date', 'Score', 'Title', 'Region'])
    df = pd.DataFrame(news_history)
    df['Date'] = pd.to_datetime(df['Date'])
    return df

def parse_rss_feed(url, region, container, date_ref):
    try:
        feed = feedparser.parse(url)
        for entry in feed.entries[:3]: 
            title = entry.title
            score = 0
            
            if region in ['US', 'EU_UK']:
                score = TextBlob(title).sentiment.polarity
                if any(x in title.lower() for x in ['beat', 'surge', 'jump', 'record', 'buy']): score += 0.3
                if any(x in title.lower() for x in ['miss', 'drop', 'plunge', 'cut', 'sell']): score -= 0.3
                
            elif region == 'TW':
                for k in MULTILINGUAL_DICT['ZH']['UP']: 
                    if k in title: score += 0.5
                for k in MULTILINGUAL_DICT['ZH']['DOWN']: 
                    if k in title: score -= 0.5
                    
            elif region == 'JP':
                for k in MULTILINGUAL_DICT['JA']['UP']: 
                    if k in title: score += 0.5
                for k in MULTILINGUAL_DICT['JA']['DOWN']: 
                    if k in title: score -= 0.5
            
            elif region == 'EU_DE': # å¾·æ–‡
                t_lower = title.lower()
                for k in MULTILINGUAL_DICT['DE']['UP']: 
                    if k in t_lower: score += 0.5
                for k in MULTILINGUAL_DICT['DE']['DOWN']: 
                    if k in t_lower: score -= 0.5
            
            if score != 0:
                container.append({
                    'Date': pd.to_datetime(entry.published).date() if hasattr(entry, 'published') else date_ref,
                    'Score': np.clip(score, -1, 1),
                    'Title': f"[{region}] {title}",
                    'Region': region
                })
    except: pass

# ==========================================
# 3. æˆ°ç•¥å¼•æ“ (å››åœ‹æ¬Šé‡ç‰ˆ)
# ==========================================
STRATEGY_DB = {
    'TSM': {'Type': 'æ©Ÿæ§‹å‹', 'W': {'Fund': 0.1, 'Tech': 0.2, 'News': 0.7}}, 
    'NVDA': {'Type': 'ä¿¡ä»°å‹', 'W': {'Fund': 0.1, 'Tech': 0.6, 'News': 0.3}},
    # URA: æ­æ´²æ¬Šé‡æ‹‰é«˜ï¼Œå› ç‚ºæ ¸èƒ½æ˜¯æ­æ´²å¤§äº‹
    'URA': {'Type': 'æ”¿ç­–å‹', 'W': {'Fund': 0.2, 'Tech': 0.3, 'News': 0.5}}, 
    'SOXL': {'Type': 'æŠ•æ©Ÿå‹', 'W': {'Fund': 0.1, 'Tech': 0.4, 'News': 0.5}},
    'DEFAULT': {'Type': 'ä¸€èˆ¬å‹', 'W': {'Fund': 0.3, 'Tech': 0.4, 'News': 0.3}}
}

def analyze_ticker_global(ticker, value_ntd):
    # 1. è‚¡åƒ¹
    df_price = yf.download(ticker, period="2y", progress=False, auto_adjust=True)
    if isinstance(df_price.columns, pd.MultiIndex):
        temp = df_price['Close'][[ticker]].copy(); temp.columns = ['Close']
        df_price = temp
    else:
        df_price = df_price[['Close']]
    
    if df_price.empty: return None

    # 2. å…¨çƒæ–°èæŒ–æ˜
    df_news = fetch_global_news(ticker, months=12)
    
    # 3. æ–°èæƒ…ç·’èåˆ
    if not df_news.empty:
        # è¨ˆç®—æ¯æ—¥åŠ æ¬Šåˆ†æ•¸ (TW/JP/EU çš„åˆ†æ•¸çµ¦äºˆåŠ æˆï¼Œå› ç‚ºæ˜¯ç¬¬ä¸€æ‰‹)
        def weighted_score(x):
            w_sum = 0
            count = 0
            for s, r in zip(x['Score'], x['Region']):
                # åœ¨åœ°æƒ…å ±åŠ æ¬Š 1.2 å€
                weight = 1.2 if r in ['TW', 'JP', 'EU_DE'] else 1.0
                w_sum += s * weight
                count += 1
            return w_sum / count if count > 0 else 0

        daily_news = df_news.groupby('Date').apply(weighted_score).rename('Score')
        df_price = df_price.join(daily_news, how='left').fillna(0)
        df_price['News_Factor'] = df_price['Score'].rolling(3).mean()
        
        # æŠ“å‡ºæœ€æ–°æ¨™é¡Œ (é¡¯ç¤ºå„åœ‹ä¾†æº)
        latest_titles = df_news.sort_values('Date').tail(3)['Title'].tolist()
        latest_news_str = " | ".join(latest_titles)
    else:
        df_price['News_Factor'] = 0
        latest_news_str = "ç„¡å…¨çƒæ–°è"

    # 4. å› å­é‹ç®—
    df_price['MA200'] = df_price['Close'].rolling(200).mean()
    df_price['Bias'] = (df_price['Close'] - df_price['MA200']) / df_price['MA200']
    df_price['Score_F'] = -np.clip(df_price['Bias'] * 2, -1, 1) 
    
    df_price['MA20'] = df_price['Close'].rolling(20).mean()
    df_price['Score_T'] = np.where(df_price['Close'] > df_price['MA20'], 0.8, -0.8)
    
    strategy = STRATEGY_DB.get(ticker, STRATEGY_DB['DEFAULT'])
    w = strategy['W']
    
    df_price['Alpha_Score'] = (df_price['Score_F'] * w['Fund']) + \
                              (df_price['Score_T'] * w['Tech']) + \
                              (df_price['News_Factor'] * w['News'])

    # 5. çœŸå¯¦æ–¹å‘å›æ¸¬ (ä¸€å¹´å‰)
    future_ret = df_price['Close'].shift(-20) - df_price['Close']
    valid_mask = (df_price.index > (datetime.now() - timedelta(days=365))) & (future_ret.notna())
    check_df = df_price[valid_mask]
    
    if not check_df.empty:
        hits = np.sign(check_df['Alpha_Score']) == np.sign(check_df['Close'].shift(-20) - check_df['Close'])
        dir_acc = hits.mean()
    else:
        dir_acc = 0.5

    # 6. çµæœ
    current_price = df_price['Close'].iloc[-1]
    current_alpha = df_price['Alpha_Score'].iloc[-1]
    vol = df_price['Close'].pct_change().rolling(30).std().iloc[-1] * np.sqrt(30)
    
    target = current_price * (1 + current_alpha * 0.05)
    buy_zone = target * (1 - vol * 1.5)
    sell_zone = target * (1 + vol * 1.5)
    
    return {
        'ä»£è™Ÿ': ticker, 'æ–¹å‘æº–ç¢ºåº¦': dir_acc,
        'ç¾åƒ¹': current_price, 'å»ºè­°è²·é»': buy_zone, 'å»ºè­°è³£é»': sell_zone,
        'æœ€æ–°æƒ…å ±': latest_news_str, 'Alphaå€¼': current_alpha, 'å¸‚å€¼(NTD)': value_ntd
    }

# ==========================================
# 4. åŸ·è¡Œä»‹é¢
# ==========================================
# åŒ¯ç‡
@st.cache_data(ttl=3600)
def get_rate():
    try: return yf.download("USDTWD=X", period="1d", progress=False)['Close'].iloc[-1].item()
    except: return 32.5
EXCHANGE_RATE = get_rate()
st.sidebar.metric("åŒ¯ç‡ (USDTWD)", f"{EXCHANGE_RATE:.2f}")

st.sidebar.header("ğŸ“‚ åŒ¯å…¥è³‡ç”¢")
uploaded_file = st.sidebar.file_uploader("ä¸Šå‚³ CSV", type=["csv"])

MY_PORTFOLIO = [{"Ticker": "URA", "Value_NTD": 100000}, {"Ticker": "TSM", "Value_NTD": 100000}] # Default URA Demo

if uploaded_file:
    try:
        df_up = pd.read_csv(uploaded_file)
        df_up.columns = [str(c).upper().strip() for c in df_up.columns]
        # (è§£æé‚è¼¯çœç•¥ï¼ŒåŒä¸Šç‰ˆ)
        clean = []
        for i, r in df_up.iterrows():
            clean.append({"Ticker": str(r[0]), "Value_NTD": 100000}) # ç°¡åŒ–ç¤ºç¯„
        MY_PORTFOLIO = clean
        st.sidebar.success(f"è®€å– {len(clean)} ç­†")
    except: pass

if st.button("ğŸš€ å•Ÿå‹•å…¨çƒæƒ…å ±ç¶² (å››åœ‹è¯é˜²)", type="primary"):
    results = []
    bar = st.progress(0)
    status = st.empty()
    
    for i, item in enumerate(MY_PORTFOLIO):
        t = item['Ticker']
        status.text(f"æ­£åœ¨æƒæ ç¾/å°/æ—¥/æ­ æƒ…å ±ç¶²: {t}... ({i+1}/{len(MY_PORTFOLIO)})")
        try:
            res = analyze_ticker_global(t, item['Value_NTD'])
            if res: results.append(res)
        except Exception as e: st.error(f"{t}: {e}")
        bar.progress((i+1)/len(MY_PORTFOLIO))
        
    status.text("âœ… å®Œæˆ")
    
    if results:
        df_res = pd.DataFrame(results)
        st.subheader("ğŸ“Š å…¨çƒæˆ°ç•¥å ±å‘Š (å«æ­æ´²è¦–è§’)")
        
        # æ¨£å¼
        show = df_res.copy()
        show['æ–¹å‘æº–ç¢ºåº¦'] = show['æ–¹å‘æº–ç¢ºåº¦'].apply(lambda x: f"{x:.0%}")
        for c in ['ç¾åƒ¹','å»ºè­°è²·é»','å»ºè­°è³£é»']: show[c] = show[c].apply(lambda x: f"${x:.2f}")
        
        st.dataframe(show.style.map(
            lambda x: 'background-color: #1f77b4; color: white' if isinstance(x, str) and '%' in x and int(x.strip('%')) > 60 else '',
            subset=['æ–¹å‘æº–ç¢ºåº¦']
        ))
        
        # æ°£æ³¡åœ–
        fig = go.Figure()
        for i, row in df_res.iterrows():
            upside = (row['å»ºè­°è³£é»'] - row['ç¾åƒ¹']) / row['ç¾åƒ¹']
            color = '#00FF7F' if row['æ–¹å‘æº–ç¢ºåº¦'] > 0.6 else '#FF4B4B'
            fig.add_trace(go.Scatter(
                x=[row['æ–¹å‘æº–ç¢ºåº¦']], y=[upside], mode='markers+text', text=[row['ä»£è™Ÿ']],
                textposition="top center", marker=dict(size=25, color=color),
                name=row['ä»£è™Ÿ']
            ))
        fig.update_layout(title="å…¨çƒæˆ°ç•¥çŸ©é™£", template="plotly_dark", height=500, xaxis_title="æº–ç¢ºåº¦", yaxis_title="æ½›åœ¨æ¼²å¹…")
        st.plotly_chart(fig, use_container_width=True)