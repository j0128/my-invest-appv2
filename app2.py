import streamlit as st
import feedparser
import pandas as pd
import numpy as np
import yfinance as yf
from textblob import TextBlob
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import time
import urllib.parse
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor

# ==========================================
# 0. é é¢è¨­å®š
# ==========================================
st.set_page_config(page_title="App 10.0 å¤©çœ¼æŒ‡æ®å®˜", layout="wide")

st.title("ğŸ¦… App 10.0: å¤©çœ¼æŒ‡æ®å®˜ (Macro-Regime Integrated)")
st.markdown("""
**çªç ´é—œéµï¼š**
1.  **åŠ å…¥ç’°å¢ƒæ¿¾ç¶² (Macro Filter)**ï¼šç›£æ§ **ç¾å…ƒ(DXY)**ã€**æ®–åˆ©ç‡(TNX)**ã€**é¢¨éšªå‚µ(HYG)**ã€‚
2.  **é †å‹¢è€Œç‚º**ï¼šç•¶ã€Œæ½®æ°´é€€å»ã€(Risk-Off) æ™‚ï¼Œå¼·åˆ¶éæ¿¾æ‰æ‰€æœ‰è²·é€²è¨Šè™Ÿï¼Œé¿å…æ¥åˆ€ã€‚
""")

# ==========================================
# 1. å¤©çœ¼ç³»çµ±ï¼šç¸½é«”ç’°å¢ƒæƒæ (Macro Scanner)
# ==========================================
@st.cache_data(ttl=3600*4)
def fetch_macro_context():
    """
    æŠ“å– DXY, TNX, HYG, VIX ä¾†åˆ¤æ–·ç›®å‰æ˜¯ Risk-On é‚„æ˜¯ Risk-Off
    """
    tickers = ['DX-Y.NYB', '^TNX', 'HYG', '^VIX']
    data = yf.download(tickers, period="1y", progress=False)['Close']
    
    # è¨ˆç®—è¶¨å‹¢ (ç°¡å–®å‡ç·šèˆ‡æ–œç‡)
    status = {}
    
    # 1. ç¾å…ƒæŒ‡æ•¸ (DXY) - è³‡é‡‘æŠ½æ°´æ©Ÿ
    dxy = data['DX-Y.NYB']
    dxy_ma20 = dxy.rolling(20).mean().iloc[-1]
    dxy_trend = "â¬†ï¸ å¼·å‹¢å¸é‡‘" if dxy.iloc[-1] > dxy_ma20 else "â¬‡ï¸ å¼±å‹¢(åˆ©å¤š)"
    
    # 2. 10å¹´æœŸæ®–åˆ©ç‡ (TNX) - ä¼°å€¼æ®ºæ‰‹
    tnx = data['^TNX']
    tnx_ma20 = tnx.rolling(20).mean().iloc[-1]
    tnx_trend = "â¬†ï¸ æ®ºä¼°å€¼" if tnx.iloc[-1] > tnx_ma20 else "â¬‡ï¸ ç©©å®š"
    
    # 3. é«˜æ”¶ç›Šå‚µ (HYG) - é¢¨éšªèƒƒç´ (è°æ˜éŒ¢)
    hyg = data['HYG']
    hyg_ma20 = hyg.rolling(20).mean().iloc[-1]
    # HYG æ¼²ä»£è¡¨è³‡é‡‘é¡˜æ„å†’éšª (Risk-On)
    risk_appetite = "ğŸ¦ Risk-On (å†’éšª)" if hyg.iloc[-1] > hyg_ma20 else "ğŸ» Risk-Off (é¿éšª)"
    
    # 4. ææ…ŒæŒ‡æ•¸ (VIX)
    vix = data['^VIX'].iloc[-1]
    vix_status = "ğŸ˜¨ ææ…Œ" if vix > 20 else "ğŸ˜Œ å¹³éœ"
    
    # ç¶œåˆåˆ¤å®šç’°å¢ƒåˆ† (Macro Score)
    # åˆ†æ•¸è¶Šé«˜è¶Šé©åˆåšå¤š
    macro_score = 0
    if dxy.iloc[-1] < dxy_ma20: macro_score += 1 # ç¾å…ƒå¼±ï¼Œå¥½
    if tnx.iloc[-1] < tnx_ma20: macro_score += 1 # åˆ©ç‡é™ï¼Œå¥½
    if hyg.iloc[-1] > hyg_ma20: macro_score += 1 # è°æ˜éŒ¢è²·å‚µï¼Œå¥½
    if vix < 20: macro_score += 1                # ä¸ææ…Œï¼Œå¥½
    
    regime = "ğŸ”´ ç´…ç‡ˆ (ç¾é‡‘ç‚ºç‹)"
    if macro_score >= 3: regime = "ğŸŸ¢ ç¶ ç‡ˆ (ç©æ¥µé€²æ”»)"
    elif macro_score == 2: regime = "ğŸŸ¡ é»ƒç‡ˆ (é¸è‚¡ä¸é¸å¸‚)"
    
    return {
        'Regime': regime,
        'Score': macro_score,
        'DXY': dxy_trend,
        'TNX': tnx_trend,
        'HYG': risk_appetite,
        'VIX': vix_status,
        'Raw_Data': data # å›æ¸¬ç”¨
    }

# ==========================================
# 2. æ–°èçˆ¬èŸ² (ä¿ç•™ä¸Šä¸€ç‰ˆåŠŸèƒ½)
# ==========================================
TICKER_MAP = {
    'TSM': {'TW': 'å°ç©é›»', 'JP': 'TSMC', 'EU': 'TSMC'},
    'NVDA': {'TW': 'è¼é”', 'JP': 'NVIDIA', 'EU': 'Nvidia'},
    'AMD': {'TW': 'è¶…å¾®', 'JP': 'AMD', 'EU': 'AMD'},
    'URA': {'TW': 'éˆ¾ç¤¦', 'JP': 'ã‚¦ãƒ©ãƒ³', 'EU': 'Uranium'},
    'SOXL': {'TW': 'åŠå°é«”', 'JP': 'åŠå°ä½“', 'EU': 'Semiconductor'},
    'BTC-USD': {'TW': 'æ¯”ç‰¹å¹£', 'JP': 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³', 'EU': 'Bitcoin'}
}

MULTILINGUAL_DICT = {
    'ZH': {'UP': ['å¤§æ¼²','æ¼²åœ','å‰µé«˜','åˆ©å¤š','çˆ†ç™¼','æ“´ç”¢','æ€¥å–®'], 'DOWN': ['å¤§è·Œ','è·Œåœ','é‡æŒ«','åˆ©ç©º','ç å–®','è¡°é€€']},
    'JA': {'UP': ['ä¸Šæ˜‡','æ€¥é¨°','æœ€é«˜å€¤','å¥½èª¿','å¢—ç›Š'], 'DOWN': ['ä¸‹è½','æ€¥è½','æœ€å®‰å€¤','ä¸èª¿','æ¸›ç›Š']},
    'DE': {'UP': ['anstieg','rekord','gewinn','kaufen'], 'DOWN': ['verlust','fallen','krise','verkaufen']}
}

@st.cache_data(ttl=3600*24)
def fetch_global_news_12m(ticker):
    news_history = []
    end_date = datetime.now()
    start_date = end_date - relativedelta(months=12) 
    map_info = TICKER_MAP.get(ticker, {})
    term_us = f"{ticker}+stock" if len(ticker) <= 4 else ticker
    term_tw = urllib.parse.quote(map_info.get('TW', ticker))
    term_jp = urllib.parse.quote(map_info.get('JP', ticker))
    term_eu = urllib.parse.quote(map_info.get('EU', ticker))

    current = start_date
    while current < end_date:
        next_month = current + relativedelta(months=1)
        d_after = current.strftime('%Y-%m-%d')
        d_before = next_month.strftime('%Y-%m-%d')
        
        urls = [
            (f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-US&gl=US&ceid=US:en", 'US'),
            (f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-GB&gl=GB&ceid=GB:en", 'EU_UK')
        ]
        if ticker in ['TSM', 'NVDA', 'AMD', '0050.TW', 'CLS', 'SOXL']:
            urls.append((f"https://news.google.com/rss/search?q={term_tw}+after:{d_after}+before:{d_before}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant", 'TW'))
        if ticker in ['TSM', 'NVDA', 'SOXL', 'URA', 'BTC-USD']:
            urls.append((f"https://news.google.com/rss/search?q={term_jp}+after:{d_after}+before:{d_before}&hl=ja&gl=JP&ceid=JP:ja", 'JP'))
        if ticker in ['URA', 'SOXL', 'CLS', 'AMD']:
            urls.append((f"https://news.google.com/rss/search?q={term_eu}+after:{d_after}+before:{d_before}&hl=de&gl=DE&ceid=DE:de", 'EU_DE'))

        for url, region in urls:
            try:
                feed = feedparser.parse(url)
                for entry in feed.entries[:2]: 
                    title = entry.title
                    pub_date = pd.to_datetime(entry.published).date() if hasattr(entry, 'published') else current.date()
                    score = 0
                    if region in ['US', 'EU_UK']:
                        score = TextBlob(title).sentiment.polarity
                        if any(x in title.lower() for x in ['beat', 'surge', 'record']): score += 0.3
                    elif region == 'TW':
                        for k in MULTILINGUAL_DICT['ZH']['UP']: 
                            if k in title: score += 0.5
                    elif region == 'JP':
                        for k in MULTILINGUAL_DICT['JA']['UP']: 
                            if k in title: score += 0.5
                    elif region == 'EU_DE':
                        for k in MULTILINGUAL_DICT['DE']['UP']: 
                            if k in title.lower(): score += 0.5
                    if score != 0:
                        news_history.append({'Ticker': ticker, 'Date': pub_date, 'Region': region, 'Title': title, 'Score': score})
            except: pass
        current = next_month
        time.sleep(0.05)
    return pd.DataFrame(news_history)

# ==========================================
# 3. å®šåƒ¹å±¤ (Quant Engine)
# ==========================================
def train_rf_model(df, ticker):
    try:
        data = df[['Close']].copy()
        data['Ret'] = data['Close'].pct_change()
        data['Vol'] = data['Ret'].rolling(20).std()
        data['SMA'] = data['Close'].rolling(20).mean()
        data['Target'] = data['Close'].shift(-22)
        data = data.dropna()
        if len(data) < 60: return None
        X = data[['Ret', 'Vol', 'SMA']]
        y = data['Target']
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X, y)
        last_row = data.iloc[[-1]][['Ret', 'Vol', 'SMA']]
        return model.predict(last_row)[0]
    except: return None

def calc_4d_target(ticker, df_price):
    current = df_price['Close'].iloc[-1]
    tr = df_price['High'] - df_price['Low']
    atr = tr.rolling(14).mean().iloc[-1]
    t_atr = current + (atr * np.sqrt(22))
    recent = df_price['Close'].iloc[-60:]
    t_fib = recent.max() + (recent.max() - recent.min()) * 0.618
    mu = df_price['Close'].pct_change().mean()
    t_mc = current * ((1 + mu) ** 22)
    t_rf = train_rf_model(df_price, ticker)
    if t_rf is None: t_rf = t_mc
    avg_target = (t_atr + t_fib + t_mc + t_rf) / 4
    return avg_target, {'ATR': t_atr, 'Fib': t_fib, 'MC': t_mc, 'RF': t_rf}

# ==========================================
# 4. å›æ¸¬å±¤ï¼šå¤©çœ¼å›æ¸¬ (God View Backtest)
# ==========================================
def run_historical_validation(df_price, df_news_ticker, macro_data):
    """
    åŠ å…¥ Macro Filter çš„å›æ¸¬
    åªæœ‰åœ¨ Macro Score >= 2 (é»ƒç‡ˆæˆ–ç¶ ç‡ˆ) æ™‚ï¼Œæ‰å…è¨±ç‹™æ“Š
    """
    df = df_price.copy()
    
    # 1. æ•´åˆæ–°è
    if not df_news_ticker.empty:
        df_news_ticker['Weight'] = df_news_ticker['Region'].apply(lambda x: 1.2 if x != 'US' else 1.0)
        df_news_ticker['W_Score'] = df_news_ticker['Score'] * df_news_ticker['Weight']
        daily_score = df_news_ticker.groupby('Date')['W_Score'].mean()
        df = df.join(daily_score, how='left').fillna(0)
        df['News_Roll'] = df['W_Score'].rolling(3).mean()
    else:
        df['News_Roll'] = 0
        
    # 2. æ•´åˆå®è§€ (Macro)
    # å°‡ HYG, DXY ç­‰æ•¸æ“šå°é½Šåˆ°å€‹è‚¡æ—¥æœŸ
    macro_aligned = macro_data.reindex(df.index).ffill()
    
    # è¨ˆç®— Macro Condition (æ­·å²ä¸Šçš„æ¯å¤©)
    # æ¢ä»¶ï¼šHYG > HYG_MA20 (Risk On) AND DXY < DXY_MA20 (Dollar Weak) -> ç°¡åŒ–ç‰ˆ Risk On
    macro_aligned['HYG_MA'] = macro_aligned['HYG'].rolling(20).mean()
    macro_aligned['Risk_On'] = macro_aligned['HYG'] > macro_aligned['HYG_MA']
    
    df = df.join(macro_aligned[['Risk_On']], how='left').fillna(False)
    
    # 3. æŠ€è¡“ç‰¹å¾µ
    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
    df['OBV_Slope'] = df['OBV'].diff(5)
    vol_mean = df['Volume'].rolling(20).mean()
    vol_std = df['Volume'].rolling(20).std()
    df['Vol_Z'] = (df['Volume'] - vol_mean) / (vol_std + 1e-9)
    
    # 4. æœªä¾†å›å ±
    df['Ret_1M'] = df['Close'].shift(-22) / df['Close'] - 1
    
    # --- å›æ¸¬: å¤©çœ¼ç‹™æ“Šæ‰‹ ---
    # æ¢ä»¶: News>0.1 & OBV>0 & Vol>1.5 & **Risk_On==True**
    sniper_mask = (df['News_Roll'] > 0.1) & (df['OBV_Slope'] > 0) & (df['Vol_Z'] > 1.5) & (df['Risk_On'] == True)
    
    sniper_opportunities = df[sniper_mask].dropna(subset=['Ret_1M'])
    
    if len(sniper_opportunities) > 0:
        sniper_wins = sniper_opportunities[sniper_opportunities['Ret_1M'] > 0]
        sniper_win_rate = len(sniper_wins) / len(sniper_opportunities)
        sniper_count = len(sniper_opportunities)
        avg_return = sniper_opportunities['Ret_1M'].mean()
    else:
        sniper_win_rate = 0.0
        sniper_count = 0
        avg_return = 0.0
        
    return sniper_win_rate, sniper_count, avg_return

# ==========================================
# 5. ä¸»ç¨‹å¼
# ==========================================
st.sidebar.title("æ§åˆ¶å°")
data_mode = st.sidebar.radio("æ•¸æ“šä¾†æº", ["1. å³æ™‚çˆ¬å–", "2. ä¸Šå‚³ CSV"])
default_tickers = ["TSM", "NVDA", "AMD", "SOXL", "URA", "CLS"]
user_tickers = st.sidebar.text_area("ä»£è™Ÿ", ", ".join(default_tickers))
ticker_list = [t.strip().upper() for t in user_tickers.split(',')]

# 1. å…ˆæŠ“å®è§€æ•¸æ“š
macro_info = fetch_macro_context()
st.subheader(f"ğŸŒ å¤©çœ¼ç’°å¢ƒæƒæ: {macro_info['Regime']} (åˆ†æ•¸: {macro_info['Score']}/4)")
c1, c2, c3, c4 = st.columns(4)
c1.metric("ç¾å…ƒ (DXY)", macro_info['DXY'])
c2.metric("æ®–åˆ©ç‡ (TNX)", macro_info['TNX'])
c3.metric("é¢¨éšªèƒƒç´ (HYG)", macro_info['HYG'])
c4.metric("ææ…Œ (VIX)", macro_info['VIX'])
st.divider()

news_df = pd.DataFrame()
run = False

if data_mode.startswith("1"):
    if st.sidebar.button("ğŸš€ å•Ÿå‹•å¤©çœ¼"):
        all_news = []
        bar = st.sidebar.progress(0)
        for i, t in enumerate(ticker_list):
            df = fetch_global_news_12m(t)
            if not df.empty: all_news.append(df)
            bar.progress((i+1)/len(ticker_list))
        if all_news:
            news_df = pd.concat(all_news, ignore_index=True)
            run = True
else:
    up = st.sidebar.file_uploader("ä¸Šå‚³ news.csv", type=['csv'])
    if up:
        news_df = pd.read_csv(up)
        news_df['Date'] = pd.to_datetime(news_df['Date'])
        run = st.sidebar.button("ğŸš€ åŸ·è¡Œ")

if run:
    st.subheader("ğŸ“Š å¤©çœ¼ç‹™æ“Šå ±å‘Š (å« Risk-On/Off æ¿¾ç¶²é©—è­‰)")
    
    results = []
    for t in ticker_list:
        df_price = yf.download(t, period="2y", progress=False, auto_adjust=True)
        if isinstance(df_price.columns, pd.MultiIndex):
            temp = df_price['Close'][[t]].copy(); temp.columns = ['Close']
            temp['Volume'] = df_price['Volume'][t]
            temp['High'] = df_price['High'][t]
            temp['Low'] = df_price['Low'][t]
            df_price = temp
        else:
            df_price = df_price[['Close', 'Volume', 'High', 'Low']]
            
        df_news_t = news_df[news_df['Ticker'] == t].copy() if not news_df.empty else pd.DataFrame()
        
        # åŸ·è¡Œå¤©çœ¼å›æ¸¬
        win_rate, count, avg_ret = run_historical_validation(df_price, df_news_t, macro_info['Raw_Data'])
        target, _ = calc_4d_target(t, df_price)
        
        # åˆ¤æ–·ç•¶ä¸‹ç‹€æ…‹ (çµåˆ Macro)
        # åªæœ‰åœ¨ Macro ç¶ ç‡ˆ/é»ƒç‡ˆæ™‚æ‰çµ¦å»ºè­°
        can_trade = macro_info['Score'] >= 2
        status = "ğŸ›‘ ç’°å¢ƒç´…ç‡ˆ (ç¦æ­¢æ“ä½œ)" if not can_trade else "â¬œ è§€æœ›"
        action = "Cash" if not can_trade else "Hold"
        
        if can_trade:
            # é€™è£¡ç°¡åŒ–åˆ¤æ–·ï¼Œå¯¦éš›å¯åŠ å…¥æ–°èé‚è¼¯
            pass 
            
        results.append({
            'Ticker': t,
            'Current': df_price['Close'].iloc[-1],
            'Target': target,
            'Sniper_Win': win_rate,
            'Sniper_Count': count,
            'Avg_Return': avg_ret,
            'Macro_Filter': "PASS" if can_trade else "BLOCK"
        })
        
    res_df = pd.DataFrame(results)
    
    show = res_df.copy()
    show['Sniper_Win'] = show['Sniper_Win'].apply(lambda x: f"{x:.0%}")
    show['Avg_Return'] = show['Avg_Return'].apply(lambda x: f"{x:+.1%}")
    show['Current'] = show['Current'].apply(lambda x: f"${x:.2f}")
    show['Target'] = show['Target'].apply(lambda x: f"${x:.2f}")

    st.dataframe(show)