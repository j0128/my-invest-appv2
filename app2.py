import streamlit as st
import feedparser
import pandas as pd
import numpy as np
import yfinance as yf
from textblob import TextBlob
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import time
import urllib.parse
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor

# ==========================================
# 0. é é¢è¨­å®š
# ==========================================
st.set_page_config(page_title="App 10.3 å¤©çœ¼æŒ‡æ®å®˜ (æœ€çµ‚ç©©å®šç‰ˆ)", layout="wide")

st.title("ğŸ¦… App 10.3: å¤©çœ¼æŒ‡æ®å®˜ (Macro + é›™é‡å›æ¸¬ + ç©©å®šä¿®å¾©)")
st.markdown("""
**ä¿®å¾©å ±å‘Šï¼š**
1.  **è§£æ±º TypeError**ï¼šä¿®æ­£ `np.sign` èˆ‡ç©ºå€¼ (NaN) è¡çªå°è‡´çš„å´©æ½°ï¼Œæ”¹ç”¨ã€Œç©æ•¸åˆ¤æ–·æ³•ã€è¨ˆç®—æº–ç¢ºåº¦ã€‚
2.  **å®Œæ•´åŠŸèƒ½**ï¼šåŒ…å«å¤©çœ¼ (Macro)ã€æ–°èçˆ¬èŸ²ã€ä»¥åŠæ•¸æ“šä¿å…¨åŠŸèƒ½ã€‚
""")

# ==========================================
# 1. å¤©çœ¼ç³»çµ± (Macro)
# ==========================================
@st.cache_data(ttl=3600*4)
def fetch_macro_context():
    tickers = ['DX-Y.NYB', '^TNX', 'HYG', '^VIX']
    data = yf.download(tickers, period="1y", progress=False)['Close']
    
    # è¶¨å‹¢åˆ¤æ–·
    dxy = data['DX-Y.NYB']
    dxy_trend = "â¬†ï¸ å¼·å‹¢" if dxy.iloc[-1] > dxy.rolling(20).mean().iloc[-1] else "â¬‡ï¸ å¼±å‹¢"
    
    tnx = data['^TNX']
    tnx_trend = "â¬†ï¸ å‡æ¯" if tnx.iloc[-1] > tnx.rolling(20).mean().iloc[-1] else "â¬‡ï¸ é™æ¯"
    
    hyg = data['HYG']
    risk_appetite = "ğŸ¦ Risk-On" if hyg.iloc[-1] > hyg.rolling(20).mean().iloc[-1] else "ğŸ» Risk-Off"
    
    vix = data['^VIX'].iloc[-1]
    
    # è©•åˆ†
    score = 0
    if dxy.iloc[-1] < dxy.rolling(20).mean().iloc[-1]: score += 1
    if tnx.iloc[-1] < tnx.rolling(20).mean().iloc[-1]: score += 1
    if hyg.iloc[-1] > hyg.rolling(20).mean().iloc[-1]: score += 1
    if vix < 20: score += 1
    
    regime = "ğŸŸ¢ ç¶ ç‡ˆ (ç©æ¥µ)" if score >= 3 else ("ğŸŸ¡ é»ƒç‡ˆ (è¬¹æ…)" if score == 2 else "ğŸ”´ ç´…ç‡ˆ (ç¾é‡‘)")
    
    return {'Regime': regime, 'Score': score, 'DXY': dxy_trend, 'TNX': tnx_trend, 'HYG': risk_appetite, 'Raw': data}

# ==========================================
# 2. æ–°èçˆ¬èŸ²
# ==========================================
TICKER_MAP = {
    'TSM': {'TW': 'å°ç©é›»', 'JP': 'TSMC', 'EU': 'TSMC'},
    'NVDA': {'TW': 'è¼é”', 'JP': 'NVIDIA', 'EU': 'Nvidia'},
    'AMD': {'TW': 'è¶…å¾®', 'JP': 'AMD', 'EU': 'AMD'},
    'URA': {'TW': 'éˆ¾ç¤¦', 'JP': 'ã‚¦ãƒ©ãƒ³', 'EU': 'Uranium'},
    'SOXL': {'TW': 'åŠå°é«”', 'JP': 'åŠå°ä½“', 'EU': 'Semiconductor'},
    'BTC-USD': {'TW': 'æ¯”ç‰¹å¹£', 'JP': 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³', 'EU': 'Bitcoin'}
}

MULTILINGUAL_DICT = {
    'ZH': {'UP': ['å¤§æ¼²','æ¼²åœ','å‰µé«˜','åˆ©å¤š','çˆ†ç™¼','æ“´ç”¢','æ€¥å–®'], 'DOWN': ['å¤§è·Œ','è·Œåœ','é‡æŒ«','åˆ©ç©º','ç å–®','è¡°é€€']},
    'JA': {'UP': ['ä¸Šæ˜‡','æ€¥é¨°','æœ€é«˜å€¤','å¥½èª¿','å¢—ç›Š'], 'DOWN': ['ä¸‹è½','æ€¥è½','æœ€å®‰å€¤','ä¸èª¿','æ¸›ç›Š']},
    'DE': {'UP': ['anstieg','rekord','gewinn','kaufen'], 'DOWN': ['verlust','fallen','krise','verkaufen']}
}

@st.cache_data(ttl=3600*24)
def fetch_global_news_12m(ticker):
    news_history = []
    end_date = datetime.now()
    start_date = end_date - relativedelta(months=12) 
    map_info = TICKER_MAP.get(ticker, {})
    term_us = f"{ticker}+stock" if len(ticker) <= 4 else ticker
    
    term_tw = urllib.parse.quote(map_info.get('TW', ticker))
    term_jp = urllib.parse.quote(map_info.get('JP', ticker))
    term_eu = urllib.parse.quote(map_info.get('EU', ticker))

    current = start_date
    while current < end_date:
        next_month = current + relativedelta(months=1)
        d_after = current.strftime('%Y-%m-%d')
        d_before = next_month.strftime('%Y-%m-%d')
        
        urls = [
            (f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-US&gl=US&ceid=US:en", 'US'),
            (f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-GB&gl=GB&ceid=GB:en", 'EU_UK')
        ]
        if ticker in ['TSM', 'NVDA', 'AMD', '0050.TW', 'CLS', 'SOXL']:
            urls.append((f"https://news.google.com/rss/search?q={term_tw}+after:{d_after}+before:{d_before}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant", 'TW'))
        if ticker in ['TSM', 'NVDA', 'SOXL', 'URA', 'BTC-USD']:
            urls.append((f"https://news.google.com/rss/search?q={term_jp}+after:{d_after}+before:{d_before}&hl=ja&gl=JP&ceid=JP:ja", 'JP'))
        if ticker in ['URA', 'SOXL', 'CLS', 'AMD']:
            urls.append((f"https://news.google.com/rss/search?q={term_eu}+after:{d_after}+before:{d_before}&hl=de&gl=DE&ceid=DE:de", 'EU_DE'))

        for url, region in urls:
            try:
                feed = feedparser.parse(url)
                for entry in feed.entries[:2]: 
                    title = entry.title
                    pub_date = pd.to_datetime(entry.published).date() if hasattr(entry, 'published') else current.date()
                    score = 0
                    if region in ['US', 'EU_UK']:
                        score = TextBlob(title).sentiment.polarity
                        if any(x in title.lower() for x in ['beat', 'surge', 'record']): score += 0.3
                    elif region == 'TW':
                        for k in MULTILINGUAL_DICT['ZH']['UP']: 
                            if k in title: score += 0.5
                    elif region == 'JP':
                        for k in MULTILINGUAL_DICT['JA']['UP']: 
                            if k in title: score += 0.5
                    elif region == 'EU_DE':
                        for k in MULTILINGUAL_DICT['DE']['UP']: 
                            if k in title.lower(): score += 0.5
                    if score != 0:
                        news_history.append({'Ticker': ticker, 'Date': pub_date, 'Region': region, 'Title': title, 'Score': score})
            except: pass
        current = next_month
        time.sleep(0.05)
    return pd.DataFrame(news_history)

# ==========================================
# 3. å®šåƒ¹å±¤
# ==========================================
def train_rf_model(df, ticker):
    try:
        data = df[['Close']].copy()
        data['Ret'] = data['Close'].pct_change()
        data['Vol'] = data['Ret'].rolling(20).std()
        data['SMA'] = data['Close'].rolling(20).mean()
        data['Target'] = data['Close'].shift(-22)
        data = data.dropna()
        if len(data) < 60: return None
        X = data[['Ret', 'Vol', 'SMA']]
        y = data['Target']
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X, y)
        last_row = data.iloc[[-1]][['Ret', 'Vol', 'SMA']]
        return model.predict(last_row)[0]
    except: return None

def calc_4d_target(ticker, df_price):
    current = df_price['Close'].iloc[-1]
    tr = df_price['High'] - df_price['Low']
    atr = tr.rolling(14).mean().iloc[-1]
    t_atr = current + (atr * np.sqrt(22))
    recent = df_price['Close'].iloc[-60:]
    t_fib = recent.max() + (recent.max() - recent.min()) * 0.618
    mu = df_price['Close'].pct_change().mean()
    t_mc = current * ((1 + mu) ** 22)
    t_rf = train_rf_model(df_price, ticker)
    if t_rf is None: t_rf = t_mc
    avg_target = (t_atr + t_fib + t_mc + t_rf) / 4
    return avg_target, {'ATR': t_atr, 'Fib': t_fib, 'MC': t_mc, 'RF': t_rf}

# ==========================================
# 4. å›æ¸¬å±¤ (é—œéµä¿®æ­£)
# ==========================================
def run_historical_validation(df_price, df_news_ticker, macro_data):
    df = df_price.copy()
    
    # A. æ–°èå°é½Š
    if not df_news_ticker.empty:
        if not pd.api.types.is_datetime64_any_dtype(df_news_ticker['Date']):
             df_news_ticker['Date'] = pd.to_datetime(df_news_ticker['Date'])

        df_news_ticker['Weight'] = df_news_ticker['Region'].apply(lambda x: 1.2 if x != 'US' else 1.0)
        df_news_ticker['W_Score'] = df_news_ticker['Score'] * df_news_ticker['Weight']
        daily_score = df_news_ticker.groupby('Date')['W_Score'].mean()
        df = df.join(daily_score, how='left').fillna(0)
        df['News_Roll'] = df['W_Score'].rolling(3).mean()
    else:
        df['News_Roll'] = 0
        
    # B. å®è§€å°é½Š
    macro_aligned = macro_data.reindex(df.index).ffill()
    macro_aligned['HYG_MA'] = macro_aligned['HYG'].rolling(20).mean()
    macro_aligned['Risk_On'] = macro_aligned['HYG'] > macro_aligned['HYG_MA']
    df = df.join(macro_aligned[['Risk_On']], how='left').fillna(False)
    
    # C. æŠ€è¡“æŒ‡æ¨™
    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
    df['OBV_Slope'] = df['OBV'].diff(5)
    df['MA20'] = df['Close'].rolling(20).mean()
    vol_mean = df['Volume'].rolling(20).mean()
    vol_std = df['Volume'].rolling(20).std()
    df['Vol_Z'] = (df['Volume'] - vol_mean) / (vol_std + 1e-9)
    
    # D. ç›®æ¨™è®Šæ•¸ (22å¤©å¾Œæ¼²è·Œ)
    df['Ret_1M'] = df['Close'].shift(-22) / df['Close'] - 1
    
    # E. Alpha è¨Šè™Ÿè¨ˆç®—
    # æŠ€è¡“å¾—åˆ†: æ”¶ç›¤ > å‡ç·š = 1, å¦å‰‡ -1
    tech_score = np.where(df['Close'] > df['MA20'], 1, -1)
    obv_score = np.sign(df['OBV_Slope']).fillna(0) # ä¿®æ­£: å¡«è£œ NaN
    
    df['Alpha_Raw'] = (df['News_Roll'] * 0.4) + (obv_score * 0.3) + (tech_score * 0.3)
    
    # --- é—œéµä¿®æ­£å€ï¼šç©©å®šè¨ˆç®—æ–¹å‘æº–ç¢ºåº¦ ---
    # 1. ç§»é™¤ NaN (å‰å¹¾ç­†æ²’æœ‰ OBV æˆ–æ˜¯å¾Œå¹¾ç­†æ²’æœ‰ Ret_1M çš„)
    valid_rows = df.dropna(subset=['Ret_1M', 'Alpha_Raw'])
    
    if len(valid_rows) > 0:
        # 2. ä¸ç”¨ np.sign æ¯”è¼ƒï¼Œæ”¹ç”¨ã€Œç›¸ä¹˜ > 0ã€é‚è¼¯ (åŒè™Ÿç›¸ä¹˜ç‚ºæ­£)
        # é¿å…æµ®é»æ•¸èˆ‡ NaN çš„å•é¡Œ
        correct = (valid_rows['Alpha_Raw'] * valid_rows['Ret_1M']) > 0
        dir_acc = correct.mean()
    else:
        dir_acc = 0.5
    
    # --- Sniper Win Rate ---
    sniper_mask = (df['News_Roll'] > 0.1) & (df['OBV_Slope'] > 0) & (df['Vol_Z'] > 1.5) & (df['Risk_On'] == True)
    sniper_opps = df[sniper_mask].dropna(subset=['Ret_1M'])
    
    if len(sniper_opps) > 0:
        sniper_wins = sniper_opps[sniper_opps['Ret_1M'] > 0]
        sniper_win_rate = len(sniper_wins) / len(sniper_opps)
        sniper_count = len(sniper_opps)
        avg_ret = sniper_opps['Ret_1M'].mean()
    else:
        sniper_win_rate = 0.0
        sniper_count = 0
        avg_ret = 0.0
        
    return dir_acc, sniper_win_rate, sniper_count, avg_ret

# ==========================================
# 5. ä¸»ç¨‹å¼
# ==========================================
st.sidebar.title("æ§åˆ¶å°")
data_mode = st.sidebar.radio("æ•¸æ“šä¾†æº", ["1. å³æ™‚çˆ¬å– (Live)", "2. ä¸Šå‚³ CSV"])
default_tickers = ["TSM", "NVDA", "AMD", "SOXL", "URA", "CLS"]
user_tickers = st.sidebar.text_area("ä»£è™Ÿ", ", ".join(default_tickers))
ticker_list = [t.strip().upper() for t in user_tickers.split(',')]

# Macro
macro_info = fetch_macro_context()
st.subheader(f"ğŸŒ å¤©çœ¼ç’°å¢ƒæƒæ: {macro_info['Regime']} (åˆ†æ•¸: {macro_info['Score']}/4)")
c1, c2, c3, c4 = st.columns(4)
c1.metric("ç¾å…ƒ", macro_info['DXY'])
c2.metric("åˆ©ç‡", macro_info['TNX'])
c3.metric("é¢¨éšª", macro_info['HYG'])
c4.metric("å»ºè­°", "ç©æ¥µ" if macro_info['Score']>=3 else "ä¿å®ˆ")
st.divider()

news_df = pd.DataFrame()
run = False

if data_mode.startswith("1"):
    if st.sidebar.button("ğŸš€ å•Ÿå‹•å…¨ç³»çµ±"):
        all_news = []
        bar = st.sidebar.progress(0)
        for i, t in enumerate(ticker_list):
            df = fetch_global_news_12m(t)
            if not df.empty: all_news.append(df)
            bar.progress((i+1)/len(ticker_list))
        if all_news:
            news_df = pd.concat(all_news, ignore_index=True)
            run = True
else:
    up = st.sidebar.file_uploader("ä¸Šå‚³ news_data.csv", type=['csv'])
    if up:
        try:
            temp = pd.read_csv(up)
            if 'Date' in temp.columns and 'Score' in temp.columns:
                news_df = temp
                news_df['Date'] = pd.to_datetime(news_df['Date'])
                run = st.sidebar.button("ğŸš€ åŸ·è¡Œ")
            else:
                st.error("âŒ æª”æ¡ˆæ ¼å¼éŒ¯èª¤ï¼Œè«‹ç¢ºèªåŒ…å« Date, Score æ¬„ä½")
        except: st.error("è®€æª”å¤±æ•—")

if run:
    st.sidebar.markdown("### ğŸ’¾ æ•¸æ“šä¿å…¨")
    st.sidebar.download_button("ğŸ“¥ ä¸‹è¼‰æ–°è CSV", news_df.to_csv(index=False).encode('utf-8'), "news_data.csv")
    
    st.subheader("ğŸ“Š å¤©çœ¼æˆ°ç•¥å ±å‘Š")
    results = []
    
    for t in ticker_list:
        df_price = yf.download(t, period="2y", progress=False, auto_adjust=True)
        if isinstance(df_price.columns, pd.MultiIndex):
            temp = df_price['Close'][[t]].copy(); temp.columns = ['Close']
            temp['Volume'] = df_price['Volume'][t]
            temp['High'] = df_price['High'][t]
            temp['Low'] = df_price['Low'][t]
            df_price = temp
        else:
            df_price = df_price[['Close', 'Volume', 'High', 'Low']]
            
        df_news_t = news_df[news_df['Ticker'] == t].copy() if not news_df.empty else pd.DataFrame()
        
        dir_acc, win_rate, count, avg_ret = run_historical_validation(df_price, df_news_t, macro_info['Raw'])
        target, _ = calc_4d_target(t, df_price)
        
        can_trade = macro_info['Score'] >= 2
        
        results.append({
            'Ticker': t,
            'Dir_Acc': dir_acc,
            'Sniper_Win': win_rate,
            'Sniper_Count': count,
            'Avg_Return': avg_ret,
            'Current': df_price['Close'].iloc[-1],
            'Target': target,
            'Upside': (target - df_price['Close'].iloc[-1]) / df_price['Close'].iloc[-1],
            'Regime': "PASS" if can_trade else "BLOCK"
        })
        
    res_df = pd.DataFrame(results)
    
    show = res_df.copy()
    show['Dir_Acc'] = show['Dir_Acc'].apply(lambda x: f"{x:.0%}")
    show['Sniper_Win'] = show['Sniper_Win'].apply(lambda x: f"{x:.0%}")
    show['Avg_Return'] = show['Avg_Return'].apply(lambda x: f"{x:+.1%}")
    show['Current'] = show['Current'].apply(lambda x: f"${x:.2f}")
    show['Target'] = show['Target'].apply(lambda x: f"${x:.2f}")
    show['Upside'] = show['Upside'].apply(lambda x: f"{x:+.1%}")

    st.dataframe(show[['Ticker', 'Dir_Acc', 'Sniper_Win', 'Sniper_Count', 'Avg_Return', 'Current', 'Target', 'Upside', 'Regime']].style.map(
        lambda x: 'background-color: #00FF7F; color: black' if 'PASS' in str(x) else 'background-color: #FF4B4B; color: white', subset=['Regime']
    ))
    
    fig = go.Figure()
    for i, row in res_df.iterrows():
        color = '#00FF7F' if row['Sniper_Win'] > 0.6 else '#FF4B4B'
        size = np.log(row['Sniper_Count'] + 1) * 15
        fig.add_trace(go.Scatter(
            x=[row['Dir_Acc']], y=[row['Sniper_Win']],
            mode='markers+text', text=[row['Ticker']],
            textposition="top center", marker=dict(size=size, color=color),
            name=row['Ticker'],
            hovertemplate="<b>%{text}</b><br>Dir Acc: %{x:.0%}<br>Win Rate: %{y:.0%}"
        ))
    fig.update_layout(title="æ¨¡å‹æ•ˆèƒ½çŸ©é™£", xaxis_title="æ–¹å‘æº–ç¢ºåº¦", yaxis_title="ç‹™æ“Šå‹ç‡", template="plotly_dark")
    st.plotly_chart(fig, use_container_width=True)