import streamlit as st
import feedparser
import pandas as pd
import numpy as np
import yfinance as yf
from textblob import TextBlob
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import time
import urllib.parse
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor

# ==========================================
# 0. é é¢è¨­å®š
# ==========================================
st.set_page_config(page_title="App 10.1 å¤©çœ¼æŒ‡æ®å®˜ (ä¿®æ­£ç‰ˆ)", layout="wide")

st.title("ğŸ¦… App 10.1: å¤©çœ¼æŒ‡æ®å®˜ (Macro + é›™é‡å›æ¸¬ + æ•¸æ“šä¿å…¨)")
st.markdown("""
**åŠŸèƒ½ä¿®å¾©ï¼š**
1.  **æ–¹å‘å›æ¸¬æ­¸ä¾†**ï¼šæ¢å¾© `Dir_Acc` (æ–¹å‘æº–ç¢ºåº¦) æŒ‡æ¨™ï¼Œæª¢é©—æ¨¡å‹é•·æœŸåˆ¤æ–·åŠ›ã€‚
2.  **æ•¸æ“šå¼·åˆ¶å­˜æª”**ï¼šçˆ¬èŸ²çµæŸå¾Œç«‹åˆ»æä¾›ä¸‹è¼‰æŒ‰éˆ•ï¼Œé¿å…é‡è¤‡æŠ“å–ã€‚
3.  **å¤©çœ¼æ¿¾ç¶²**ï¼šçµåˆ DXY/TNX/HYG å®è§€æŒ‡æ¨™ï¼Œåªåœ¨é †é¢¨æ™‚å‡ºæ“Šã€‚
""")

# ==========================================
# 1. å¤©çœ¼ç³»çµ±ï¼šç¸½é«”ç’°å¢ƒæƒæ
# ==========================================
@st.cache_data(ttl=3600*4)
def fetch_macro_context():
    tickers = ['DX-Y.NYB', '^TNX', 'HYG', '^VIX']
    data = yf.download(tickers, period="1y", progress=False)['Close']
    
    # åˆ¤æ–·è¶¨å‹¢
    dxy = data['DX-Y.NYB']
    dxy_ma20 = dxy.rolling(20).mean().iloc[-1]
    dxy_trend = "â¬†ï¸ å¼·å‹¢(ä¸åˆ©)" if dxy.iloc[-1] > dxy_ma20 else "â¬‡ï¸ å¼±å‹¢(æœ‰åˆ©)"
    
    tnx = data['^TNX']
    tnx_ma20 = tnx.rolling(20).mean().iloc[-1]
    tnx_trend = "â¬†ï¸ å‡æ¯(ä¸åˆ©)" if tnx.iloc[-1] > tnx_ma20 else "â¬‡ï¸ é™æ¯(æœ‰åˆ©)"
    
    hyg = data['HYG']
    hyg_ma20 = hyg.rolling(20).mean().iloc[-1]
    risk_appetite = "ğŸ¦ Risk-On" if hyg.iloc[-1] > hyg_ma20 else "ğŸ» Risk-Off"
    
    vix = data['^VIX'].iloc[-1]
    
    # è©•åˆ† (æ»¿åˆ†4åˆ†)
    score = 0
    if dxy.iloc[-1] < dxy_ma20: score += 1
    if tnx.iloc[-1] < tnx_ma20: score += 1
    if hyg.iloc[-1] > hyg_ma20: score += 1
    if vix < 20: score += 1
    
    regime = "ğŸŸ¢ ç¶ ç‡ˆ (ç©æ¥µ)" if score >= 3 else ("ğŸŸ¡ é»ƒç‡ˆ (è¬¹æ…)" if score == 2 else "ğŸ”´ ç´…ç‡ˆ (ç¾é‡‘)")
    
    return {'Regime': regime, 'Score': score, 'DXY': dxy_trend, 'TNX': tnx_trend, 'HYG': risk_appetite, 'Raw': data}

# ==========================================
# 2. æ–°èçˆ¬èŸ² (å››åœ‹æ ¸å¿ƒ)
# ==========================================
TICKER_MAP = {
    'TSM': {'TW': 'å°ç©é›»', 'JP': 'TSMC', 'EU': 'TSMC'},
    'NVDA': {'TW': 'è¼é”', 'JP': 'NVIDIA', 'EU': 'Nvidia'},
    'AMD': {'TW': 'è¶…å¾®', 'JP': 'AMD', 'EU': 'AMD'},
    'URA': {'TW': 'éˆ¾ç¤¦', 'JP': 'ã‚¦ãƒ©ãƒ³', 'EU': 'Uranium'},
    'SOXL': {'TW': 'åŠå°é«”', 'JP': 'åŠå°ä½“', 'EU': 'Semiconductor'},
    'BTC-USD': {'TW': 'æ¯”ç‰¹å¹£', 'JP': 'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³', 'EU': 'Bitcoin'}
}

MULTILINGUAL_DICT = {
    'ZH': {'UP': ['å¤§æ¼²','æ¼²åœ','å‰µé«˜','åˆ©å¤š','çˆ†ç™¼','æ“´ç”¢','æ€¥å–®'], 'DOWN': ['å¤§è·Œ','è·Œåœ','é‡æŒ«','åˆ©ç©º','ç å–®','è¡°é€€']},
    'JA': {'UP': ['ä¸Šæ˜‡','æ€¥é¨°','æœ€é«˜å€¤','å¥½èª¿','å¢—ç›Š'], 'DOWN': ['ä¸‹è½','æ€¥è½','æœ€å®‰å€¤','ä¸èª¿','æ¸›ç›Š']},
    'DE': {'UP': ['anstieg','rekord','gewinn','kaufen'], 'DOWN': ['verlust','fallen','krise','verkaufen']}
}

@st.cache_data(ttl=3600*24)
def fetch_global_news_12m(ticker):
    news_history = []
    end_date = datetime.now()
    start_date = end_date - relativedelta(months=12) 
    map_info = TICKER_MAP.get(ticker, {})
    term_us = f"{ticker}+stock" if len(ticker) <= 4 else ticker
    term_tw = urllib.parse.quote(map_info.get('TW', ticker))
    term_jp = urllib.parse.quote(map_info.get('JP', ticker))
    term_eu = urllib.parse.quote(map_info.get('EU', ticker))

    current = start_date
    while current < end_date:
        next_month = current + relativedelta(months=1)
        d_after = current.strftime('%Y-%m-%d')
        d_before = next_month.strftime('%Y-%m-%d')
        
        urls = [
            (f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-US&gl=US&ceid=US:en", 'US'),
            (f"https://news.google.com/rss/search?q={term_us}+after:{d_after}+before:{d_before}&hl=en-GB&gl=GB&ceid=GB:en", 'EU_UK')
        ]
        if ticker in ['TSM', 'NVDA', 'AMD', '0050.TW', 'CLS', 'SOXL']:
            urls.append((f"https://news.google.com/rss/search?q={term_tw}+after:{d_after}+before:{d_before}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant", 'TW'))
        if ticker in ['TSM', 'NVDA', 'SOXL', 'URA', 'BTC-USD']:
            urls.append((f"https://news.google.com/rss/search?q={term_jp}+after:{d_after}+before:{d_before}&hl=ja&gl=JP&ceid=JP:ja", 'JP'))
        if ticker in ['URA', 'SOXL', 'CLS', 'AMD']:
            urls.append((f"https://news.google.com/rss/search?q={term_eu}+after:{d_after}+before:{d_before}&hl=de&gl=DE&ceid=DE:de", 'EU_DE'))

        for url, region in urls:
            try:
                feed = feedparser.parse(url)
                for entry in feed.entries[:2]: 
                    title = entry.title
                    pub_date = pd.to_datetime(entry.published).date() if hasattr(entry, 'published') else current.date()
                    score = 0
                    if region in ['US', 'EU_UK']:
                        score = TextBlob(title).sentiment.polarity
                        if any(x in title.lower() for x in ['beat', 'surge', 'record']): score += 0.3
                    elif region == 'TW':
                        for k in MULTILINGUAL_DICT['ZH']['UP']: 
                            if k in title: score += 0.5
                    elif region == 'JP':
                        for k in MULTILINGUAL_DICT['JA']['UP']: 
                            if k in title: score += 0.5
                    elif region == 'EU_DE':
                        for k in MULTILINGUAL_DICT['DE']['UP']: 
                            if k in title.lower(): score += 0.5
                    if score != 0:
                        news_history.append({'Ticker': ticker, 'Date': pub_date, 'Region': region, 'Title': title, 'Score': score})
            except: pass
        current = next_month
        time.sleep(0.05)
    return pd.DataFrame(news_history)

# ==========================================
# 3. å®šåƒ¹å±¤ (Quant Engine)
# ==========================================
def train_rf_model(df, ticker):
    try:
        data = df[['Close']].copy()
        data['Ret'] = data['Close'].pct_change()
        data['Vol'] = data['Ret'].rolling(20).std()
        data['SMA'] = data['Close'].rolling(20).mean()
        data['Target'] = data['Close'].shift(-22)
        data = data.dropna()
        if len(data) < 60: return None
        X = data[['Ret', 'Vol', 'SMA']]
        y = data['Target']
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X, y)
        last_row = data.iloc[[-1]][['Ret', 'Vol', 'SMA']]
        return model.predict(last_row)[0]
    except: return None

def calc_4d_target(ticker, df_price):
    current = df_price['Close'].iloc[-1]
    tr = df_price['High'] - df_price['Low']
    atr = tr.rolling(14).mean().iloc[-1]
    t_atr = current + (atr * np.sqrt(22))
    recent = df_price['Close'].iloc[-60:]
    t_fib = recent.max() + (recent.max() - recent.min()) * 0.618
    mu = df_price['Close'].pct_change().mean()
    t_mc = current * ((1 + mu) ** 22)
    t_rf = train_rf_model(df_price, ticker)
    if t_rf is None: t_rf = t_mc
    avg_target = (t_atr + t_fib + t_mc + t_rf) / 4
    return avg_target, {'ATR': t_atr, 'Fib': t_fib, 'MC': t_mc, 'RF': t_rf}

# ==========================================
# 4. å›æ¸¬å±¤ï¼šé›™é‡é©—è­‰ (Dir_Acc + Sniper)
# ==========================================
def run_historical_validation(df_price, df_news_ticker, macro_data):
    df = df_price.copy()
    
    # A. æ•´åˆæ–°è
    if not df_news_ticker.empty:
        df_news_ticker['Weight'] = df_news_ticker['Region'].apply(lambda x: 1.2 if x != 'US' else 1.0)
        df_news_ticker['W_Score'] = df_news_ticker['Score'] * df_news_ticker['Weight']
        daily_score = df_news_ticker.groupby('Date')['W_Score'].mean()
        df = df.join(daily_score, how='left').fillna(0)
        df['News_Roll'] = df['W_Score'].rolling(3).mean()
    else:
        df['News_Roll'] = 0
        
    # B. æ•´åˆå®è§€ (Macro Risk-On/Off)
    macro_aligned = macro_data.reindex(df.index).ffill()
    macro_aligned['HYG_MA'] = macro_aligned['HYG'].rolling(20).mean()
    macro_aligned['Risk_On'] = macro_aligned['HYG'] > macro_aligned['HYG_MA']
    df = df.join(macro_aligned[['Risk_On']], how='left').fillna(False)
    
    # C. æŠ€è¡“ç‰¹å¾µ
    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
    df['OBV_Slope'] = df['OBV'].diff(5)
    df['MA20'] = df['Close'].rolling(20).mean()
    vol_mean = df['Volume'].rolling(20).mean()
    vol_std = df['Volume'].rolling(20).std()
    df['Vol_Z'] = (df['Volume'] - vol_mean) / (vol_std + 1e-9)
    
    # D. æœªä¾†å›å ± (22å¤©å¾Œ)
    df['Ret_1M'] = df['Close'].shift(-22) / df['Close'] - 1
    
    # --- æŒ‡æ¨™ 1: æ–¹å‘æº–ç¢ºåº¦ (Dir_Acc) ---
    # é‚è¼¯: ç¶œåˆåˆ†æ•¸ (News + Tech) æ˜¯å¦é æ¸¬å°äº†æ¼²è·Œ?
    df['Alpha_Raw'] = (df['News_Roll'] * 0.4) + (np.sign(df['OBV_Slope']) * 0.3) + (np.where(df['Close']>df['MA20'], 1, -1) * 0.3)
    valid_rows = df.dropna(subset=['Ret_1M'])
    
    if len(valid_rows) > 0:
        # åŒè™Ÿå³ç‚ºé æ¸¬æ­£ç¢º
        correct = np.sign(valid_rows['Alpha_Raw']) == np.sign(valid_rows['Ret_1M'])
        dir_acc = correct.mean()
    else:
        dir_acc = 0.5
    
    # --- æŒ‡æ¨™ 2: å¤©çœ¼ç‹™æ“Šå‹ç‡ (Sniper Win Rate) ---
    # æ¢ä»¶: News>0.1 & OBV>0 & Vol>1.5 & Risk_On (å®è§€ç¶ ç‡ˆ)
    sniper_mask = (df['News_Roll'] > 0.1) & (df['OBV_Slope'] > 0) & (df['Vol_Z'] > 1.5) & (df['Risk_On'] == True)
    
    sniper_opps = df[sniper_mask].dropna(subset=['Ret_1M'])
    
    if len(sniper_opps) > 0:
        sniper_wins = sniper_opps[sniper_opps['Ret_1M'] > 0]
        sniper_win_rate = len(sniper_wins) / len(sniper_opps)
        sniper_count = len(sniper_opps)
        avg_ret = sniper_opps['Ret_1M'].mean()
    else:
        sniper_win_rate = 0.0
        sniper_count = 0
        avg_ret = 0.0
        
    return dir_acc, sniper_win_rate, sniper_count, avg_ret

# ==========================================
# 5. ä¸»ç¨‹å¼
# ==========================================
st.sidebar.title("æ§åˆ¶å°")
data_mode = st.sidebar.radio("æ•¸æ“šä¾†æº", ["1. å³æ™‚çˆ¬å– (Live)", "2. ä¸Šå‚³ CSV"])
default_tickers = ["TSM", "NVDA", "AMD", "SOXL", "URA", "CLS"]
user_tickers = st.sidebar.text_area("ä»£è™Ÿ (é€—è™Ÿåˆ†éš”)", ", ".join(default_tickers))
ticker_list = [t.strip().upper() for t in user_tickers.split(',')]

# å®è§€å„€è¡¨æ¿
macro_info = fetch_macro_context()
st.subheader(f"ğŸŒ å¤©çœ¼ç’°å¢ƒæƒæ: {macro_info['Regime']} (åˆ†æ•¸: {macro_info['Score']}/4)")
c1, c2, c3, c4 = st.columns(4)
c1.metric("ç¾å…ƒ (DXY)", macro_info['DXY'])
c2.metric("æ®–åˆ©ç‡ (TNX)", macro_info['TNX'])
c3.metric("é¢¨éšªèƒƒç´ (HYG)", macro_info['HYG'])
c4.metric("å®è§€å»ºè­°", "ç©æ¥µé€²å ´" if macro_info['Score']>=3 else "ä¿å®ˆæ“ä½œ")
st.divider()

news_df = pd.DataFrame()
run = False

if data_mode.startswith("1"):
    if st.sidebar.button("ğŸš€ å•Ÿå‹•å…¨ç³»çµ±"):
        all_news = []
        bar = st.sidebar.progress(0)
        for i, t in enumerate(ticker_list):
            df = fetch_global_news_12m(t)
            if not df.empty: all_news.append(df)
            bar.progress((i+1)/len(ticker_list))
        if all_news:
            news_df = pd.concat(all_news, ignore_index=True)
            run = True
else:
    up = st.sidebar.file_uploader("ä¸Šå‚³ news_data.csv", type=['csv'])
    if up:
        news_df = pd.read_csv(up)
        news_df['Date'] = pd.to_datetime(news_df['Date'])
        run = st.sidebar.button("ğŸš€ åŸ·è¡Œåˆ†æ")

if run:
    # 1. å¼·åˆ¶å­˜æª”æŒ‰éˆ• (æ”¾åœ¨æœ€é¡¯çœ¼è™•)
    st.sidebar.markdown("### ğŸ’¾ æ•¸æ“šä¿å…¨")
    st.sidebar.download_button(
        "ğŸ“¥ ä¸‹è¼‰æ–°èè³‡æ–™ (CSV)",
        news_df.to_csv(index=False).encode('utf-8'),
        "news_data.csv",
        "text/csv",
        key='download-csv'
    )
    
    st.subheader("ğŸ“Š å¤©çœ¼æˆ°ç•¥å ±å‘Š")
    results = []
    
    for t in ticker_list:
        # ä¸‹è¼‰å€‹è‚¡æ•¸æ“š
        df_price = yf.download(t, period="2y", progress=False, auto_adjust=True)
        if isinstance(df_price.columns, pd.MultiIndex):
            temp = df_price['Close'][[t]].copy(); temp.columns = ['Close']
            temp['Volume'] = df_price['Volume'][t]
            temp['High'] = df_price['High'][t]
            temp['Low'] = df_price['Low'][t]
            df_price = temp
        else:
            df_price = df_price[['Close', 'Volume', 'High', 'Low']]
            
        df_news_t = news_df[news_df['Ticker'] == t].copy() if not news_df.empty else pd.DataFrame()
        
        # åŸ·è¡Œé›™é‡å›æ¸¬
        dir_acc, win_rate, count, avg_ret = run_historical_validation(df_price, df_news_t, macro_info['Raw'])
        target, _ = calc_4d_target(t, df_price)
        
        # ç•¶ä¸‹å»ºè­°
        can_trade = macro_info['Score'] >= 2
        status = "ğŸ›‘ ç’°å¢ƒç´…ç‡ˆ" if not can_trade else "â¬œ è§€æœ›"
        action = "Cash" if not can_trade else "Hold"
        
        results.append({
            'Ticker': t,
            'Dir_Acc': dir_acc,       # è£œå›é€™æ¬„
            'Sniper_Win': win_rate,
            'Sniper_Count': count,
            'Avg_Return': avg_ret,
            'Current': df_price['Close'].iloc[-1],
            'Target': target,
            'Upside': (target - df_price['Close'].iloc[-1]) / df_price['Close'].iloc[-1]
        })
        
    res_df = pd.DataFrame(results)
    
    # é¡¯ç¤ºå„ªåŒ–
    show = res_df.copy()
    show['Dir_Acc'] = show['Dir_Acc'].apply(lambda x: f"{x:.0%}")
    show['Sniper_Win'] = show['Sniper_Win'].apply(lambda x: f"{x:.0%}")
    show['Avg_Return'] = show['Avg_Return'].apply(lambda x: f"{x:+.1%}")
    show['Current'] = show['Current'].apply(lambda x: f"${x:.2f}")
    show['Target'] = show['Target'].apply(lambda x: f"${x:.2f}")
    show['Upside'] = show['Upside'].apply(lambda x: f"{x:+.1%}")

    st.dataframe(show)
    
    # æ°£æ³¡åœ–
    fig = go.Figure()
    for i, row in res_df.iterrows():
        color = '#00FF7F' if row['Sniper_Win'] > 0.6 else '#FF4B4B'
        size = np.log(row['Sniper_Count'] + 1) * 15
        fig.add_trace(go.Scatter(
            x=[row['Dir_Acc']], y=[row['Sniper_Win']],
            mode='markers+text', text=[row['Ticker']],
            textposition="top center", marker=dict(size=size, color=color),
            name=row['Ticker'],
            hovertemplate="<b>%{text}</b><br>é•·æœŸæ–¹å‘æº–åº¦: %{x:.0%}<br>å¤©çœ¼ç‹™æ“Šå‹ç‡: %{y:.0%}"
        ))
    fig.update_layout(title="æ¨¡å‹æ•ˆèƒ½çŸ©é™£ (X=åŸºæœ¬åŠŸ, Y=å¿…æ®ºæŠ€)", xaxis_title="æ–¹å‘æº–ç¢ºåº¦", yaxis_title="ç‹™æ“Šå‹ç‡", template="plotly_dark")
    st.plotly_chart(fig, use_container_width=True)